{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b089727a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: noisereduce in /opt/homebrew/lib/python3.11/site-packages (3.0.3)\n",
      "Requirement already satisfied: scipy in /opt/homebrew/lib/python3.11/site-packages (from noisereduce) (1.13.0)\n",
      "Requirement already satisfied: matplotlib in /opt/homebrew/lib/python3.11/site-packages (from noisereduce) (3.8.1)\n",
      "Requirement already satisfied: numpy in /opt/homebrew/lib/python3.11/site-packages (from noisereduce) (1.26.1)\n",
      "Requirement already satisfied: tqdm in /opt/homebrew/lib/python3.11/site-packages (from noisereduce) (4.66.1)\n",
      "Requirement already satisfied: joblib in /opt/homebrew/lib/python3.11/site-packages (from noisereduce) (1.3.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib->noisereduce) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib->noisereduce) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib->noisereduce) (4.44.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib->noisereduce) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib->noisereduce) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib->noisereduce) (10.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib->noisereduce) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib->noisereduce) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/homebrew/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib->noisereduce) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n",
      "Collecting librosa\n",
      "  Downloading librosa-0.11.0-py3-none-any.whl.metadata (8.7 kB)\n",
      "Collecting audioread>=2.1.9 (from librosa)\n",
      "  Downloading audioread-3.1.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting numba>=0.51.0 (from librosa)\n",
      "  Downloading numba-0.63.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: numpy>=1.22.3 in /opt/homebrew/lib/python3.11/site-packages (from librosa) (1.26.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/homebrew/lib/python3.11/site-packages (from librosa) (1.13.0)\n",
      "Requirement already satisfied: scikit-learn>=1.1.0 in /opt/homebrew/lib/python3.11/site-packages (from librosa) (1.4.2)\n",
      "Requirement already satisfied: joblib>=1.0 in /opt/homebrew/lib/python3.11/site-packages (from librosa) (1.3.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /Users/omari/Library/Python/3.11/lib/python/site-packages (from librosa) (5.1.1)\n",
      "Collecting soundfile>=0.12.1 (from librosa)\n",
      "  Downloading soundfile-0.13.1-py2.py3-none-macosx_11_0_arm64.whl.metadata (16 kB)\n",
      "Collecting pooch>=1.1 (from librosa)\n",
      "  Downloading pooch-1.8.2-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting soxr>=0.3.2 (from librosa)\n",
      "  Downloading soxr-1.0.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: typing_extensions>=4.1.1 in /opt/homebrew/lib/python3.11/site-packages (from librosa) (4.11.0)\n",
      "Collecting lazy_loader>=0.1 (from librosa)\n",
      "  Downloading lazy_loader-0.4-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting msgpack>=1.0 (from librosa)\n",
      "  Downloading msgpack-1.1.2-cp311-cp311-macosx_11_0_arm64.whl.metadata (8.1 kB)\n",
      "Requirement already satisfied: packaging in /opt/homebrew/lib/python3.11/site-packages (from lazy_loader>=0.1->librosa) (23.2)\n",
      "Collecting llvmlite<0.47,>=0.46.0dev0 (from numba>=0.51.0->librosa)\n",
      "  Downloading llvmlite-0.46.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /Users/omari/Library/Python/3.11/lib/python/site-packages (from pooch>=1.1->librosa) (4.0.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/homebrew/lib/python3.11/site-packages (from pooch>=1.1->librosa) (2.31.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/homebrew/lib/python3.11/site-packages (from scikit-learn>=1.1.0->librosa) (3.5.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /opt/homebrew/lib/python3.11/site-packages (from soundfile>=0.12.1->librosa) (1.17.1)\n",
      "Requirement already satisfied: pycparser in /opt/homebrew/lib/python3.11/site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/lib/python3.11/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/lib/python3.11/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/lib/python3.11/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/lib/python3.11/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2023.7.22)\n",
      "Downloading librosa-0.11.0-py3-none-any.whl (260 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m260.7/260.7 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading audioread-3.1.0-py3-none-any.whl (23 kB)\n",
      "Downloading lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
      "Downloading msgpack-1.1.2-cp311-cp311-macosx_11_0_arm64.whl (84 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m84.9/84.9 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numba-0.63.1-cp311-cp311-macosx_11_0_arm64.whl (2.7 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pooch-1.8.2-py3-none-any.whl (64 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m64.6/64.6 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading soundfile-0.13.1-py2.py3-none-macosx_11_0_arm64.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading soxr-1.0.0-cp311-cp311-macosx_11_0_arm64.whl (165 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m165.2/165.2 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading llvmlite-0.46.0-cp311-cp311-macosx_11_0_arm64.whl (37.2 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m37.2/37.2 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: soxr, msgpack, llvmlite, lazy_loader, audioread, soundfile, pooch, numba, librosa\n",
      "Successfully installed audioread-3.1.0 lazy_loader-0.4 librosa-0.11.0 llvmlite-0.46.0 msgpack-1.1.2 numba-0.63.1 pooch-1.8.2 soundfile-0.13.1 soxr-1.0.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install noisereduce\n",
    "!pip install librosa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2adc8506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 35000 audio files to process\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing audio files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35000/35000 [05:55<00:00, 98.44it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Complete:\n",
      "  Successful: 35000 files\n",
      "  Failed: 0 files\n",
      "Processed 35000 files\n",
      "Output saved to: Emotion Speech Dataset/processed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# quick_process.py\n",
    "from pathlib import Path\n",
    "\n",
    "def quick_bulk_process(input_folder, output_folder=None):\n",
    "    \"\"\"\n",
    "    One-line bulk processing for common use cases\n",
    "    \"\"\"\n",
    "    if output_folder is None:\n",
    "        output_folder = Path(input_folder) / 'processed'\n",
    "    \n",
    "    # Create processor\n",
    "    processor = AudioBulkProcessor(target_sr=16000, n_jobs=1)\n",
    "    \n",
    "    # Process\n",
    "    results = processor.process_directory(\n",
    "        input_dir=input_folder,\n",
    "        output_dir=output_folder,\n",
    "        normalize=True,\n",
    "        noise_reduce=True,\n",
    "        remove_silence=True,\n",
    "        norm_params={'method': 'peak', 'target_level': -1.0},\n",
    "        noise_params={'method': 'spectral_gate', 'prop_decrease': 0.9},\n",
    "        silence_params={'top_db': 25}\n",
    "    )\n",
    "    \n",
    "    print(f\"Processed {len([r for r in results if r[0]])} files\")\n",
    "    print(f\"Output saved to: {output_folder}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Usage\n",
    "if __name__ == '__main__':\n",
    "    # Just change this path\n",
    "    quick_bulk_process('Emotion Speech Dataset/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d86eef",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8117d44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install librosa pandas numpy h5py tqdm -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdfe657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ğŸµ UNIFIED FEATURE EXTRACTION PIPELINE\n",
      "============================================================\n",
      "\n",
      "ğŸ“Š Step 1: Scanning datasets and standardizing emotions...\n",
      "\n",
      "ğŸ“ Scanning jl-corpus...\n",
      "   Found 12160 audio files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Processing jl-corpus: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12160/12160 [00:00<00:00, 583882.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   âœ… Processed: 5824, âŒ Skipped: 6336\n",
      "\n",
      "ğŸ“ Scanning TESS...\n",
      "   Found 5600 audio files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Processing TESS: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5600/5600 [00:00<00:00, 319036.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   âœ… Processed: 5600, âŒ Skipped: 0\n",
      "\n",
      "ğŸ“ Scanning ESD...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Found 35000 audio files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Processing ESD: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35000/35000 [00:00<00:00, 603323.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   âœ… Processed: 35000, âŒ Skipped: 0\n",
      "\n",
      "ğŸ“„ Scanning CSV: ML - Combined Dataset (RAVDESS - SAVEE).csv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Processing CSV: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1224/1224 [00:00<00:00, 40611.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   âœ… Processed: 1224\n",
      "   âŒ Skipped (emotion): 0\n",
      "   âš ï¸ Missing files: 0\n",
      "\n",
      "âœ… Total valid files: 47648\n",
      "\n",
      "ğŸ“ˆ Emotion Distribution:\n",
      "  angry: 9508 files\n",
      "  happy: 9508 files\n",
      "  neutral: 9472 files\n",
      "  sad: 9508 files\n",
      "  surprise: 9652 files\n",
      "\n",
      "ğŸ“ Step 2: Creating unified feature file...\n",
      "\n",
      "âš¡ Step 3: Extracting MFCC features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47648/47648 [19:25<00:00, 40.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Feature extraction complete!\n",
      "   Successful: 47648 files\n",
      "   Failed: 0 files\n",
      "   Output file: unified_audio_features.h5\n",
      "   File size: 0.21 GB\n",
      "\n",
      "ğŸ“‹ Creating summary CSV...\n",
      "âœ… Summary saved to: features_summary.csv\n",
      "ğŸ“Š Feature File Information:\n",
      "   Total files: 47648\n",
      "   Sample rate: 22050\n",
      "   MFCC features: 13\n",
      "\n",
      "ğŸ­ Emotion Distribution:\n",
      "   angry: 9508 files\n",
      "   happy: 9508 files\n",
      "   neutral: 9472 files\n",
      "   sad: 9508 files\n",
      "   surprise: 9652 files\n",
      "\n",
      "ğŸ“ Dataset Distribution:\n",
      "   ESD: 35000 files\n",
      "   RAVDESS: 864 files\n",
      "   SAVEE: 360 files\n",
      "   TESS: 5600 files\n",
      "   jl-corpus: 5824 files\n",
      "\n",
      "ğŸ“¥ Example: Loading features for model training...\n",
      "Loaded 47648 feature vectors\n",
      "Feature shape: (129, 13)\n",
      "Labels: (array(['angry', 'happy', 'neutral', 'sad', 'surprise'], dtype='<U8'), array([9508, 9508, 9472, 9508, 9652]))\n",
      "\n",
      "ğŸ’¾ To download in Colab:\n",
      "from google.colab import files\n",
      "files.download('unified_audio_features.h5')\n",
      "files.download('features_summary.csv')\n"
     ]
    }
   ],
   "source": [
    "# =====================\n",
    "# 1. SETUP AND CONFIGURATION\n",
    "# =====================\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import h5py\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuration\n",
    "SAMPLE_RATE = 22050\n",
    "N_MFCC = 13\n",
    "N_FFT = 2048\n",
    "HOP_LENGTH = 512\n",
    "TARGET_EMOTIONS = ['sad', 'happy', 'angry', 'surprise', 'neutral']\n",
    "\n",
    "# --- EXISTING FOLDER-BASED DATASETS ---\n",
    "DATASET_PATHS = {\n",
    "    'jl-corpus': '/Users/omari/Master Classes/ML/jl-corpus/processed',\n",
    "    'TESS': '/Users/omari/Master Classes/ML/TESS/processed',\n",
    "    'ESD': '/Users/omari/Master Classes/ML/Emotion Speech Dataset/processed'\n",
    "}\n",
    "\n",
    "# --- NEW CSV-BASED DATASETS EXTENSION ---\n",
    "# Configuration for the additional datasets (RAVDESS, SAVEE)\n",
    "CSV_DATASETS = [\n",
    "    {\n",
    "        'path': 'ML - Combined Dataset (RAVDESS - SAVEE).csv',\n",
    "        # Adjust this path to where the \"ravdess-emotional-speech-audio\" folder sits\n",
    "        'base_dir': '/Users/omari/Master Classes/ML/' \n",
    "    }\n",
    "]\n",
    "\n",
    "# =====================\n",
    "# 2. EMOTION MAPPING AND STANDARDIZATION\n",
    "# =====================\n",
    "\n",
    "# Comprehensive emotion mapping dictionary\n",
    "EMOTION_MAPPING = {\n",
    "    # Standard emotions (already correct)\n",
    "    'sad': 'sad',\n",
    "    'happy': 'happy',\n",
    "    'angry': 'angry',\n",
    "    'surprise': 'surprise',\n",
    "    'neutral': 'neutral',\n",
    "    \n",
    "    # TESS specific variations\n",
    "    'pleasant_surprise': 'surprise',\n",
    "    'pleasant surprise': 'surprise',\n",
    "    'ps': 'surprise',  # TESS abbreviation\n",
    "    'fear': 'surprise',  # Map fear to surprise for consistency\n",
    "    'disgust': 'angry',  # Map disgust to angry\n",
    "    'fearful': 'surprise',\n",
    "    'disgusted': 'angry',\n",
    "    \n",
    "    # Adjective/Noun variations\n",
    "    'sadness': 'sad',\n",
    "    'happiness': 'happy',\n",
    "    'anger': 'angry',\n",
    "    'surprised': 'surprise',\n",
    "    \n",
    "    # ESD variations\n",
    "    'Surprise': 'surprise',\n",
    "    'Angry': 'angry',\n",
    "    'Happy': 'happy',\n",
    "    'Sad': 'sad',\n",
    "    'Neutral': 'neutral',\n",
    "    \n",
    "    # JL Corpus variations\n",
    "    'SAD': 'sad',\n",
    "    'HAPPY': 'happy',\n",
    "    'ANGRY': 'angry',\n",
    "    'SURPRISE': 'surprise',\n",
    "    'NEUTRAL': 'neutral',\n",
    "    \n",
    "    # Additional common variations\n",
    "    'joy': 'happy',\n",
    "    'joyful': 'happy',\n",
    "    'angryanger': 'angry',\n",
    "    'neutralneutral': 'neutral',\n",
    "}\n",
    "\n",
    "def standardize_emotion(input_emotion, filename, dataset_name):\n",
    "    \"\"\"\n",
    "    Standardize emotion names across all datasets\n",
    "    \"\"\"\n",
    "    if not input_emotion:\n",
    "        return None\n",
    "    \n",
    "    input_lower = str(input_emotion).lower().strip().replace(' ', '_')\n",
    "    \n",
    "    # Direct mapping first\n",
    "    if input_lower in EMOTION_MAPPING:\n",
    "        return EMOTION_MAPPING[input_lower]\n",
    "    \n",
    "    # Check for partial matches\n",
    "    for key in EMOTION_MAPPING:\n",
    "        if key in input_lower:\n",
    "            return EMOTION_MAPPING[key]\n",
    "    \n",
    "    # Dataset-specific heuristics\n",
    "    if dataset_name == 'TESS':\n",
    "        # TESS patterns: OAF_back_angry.wav or YAF_back_sad.wav\n",
    "        for emotion in TARGET_EMOTIONS:\n",
    "            if f'_{emotion}' in filename.lower() or f'-{emotion}' in filename.lower():\n",
    "                return emotion\n",
    "    \n",
    "    elif dataset_name == 'jl-corpus':\n",
    "        # JL patterns: filename contains emotion\n",
    "        for emotion in TARGET_EMOTIONS:\n",
    "            if emotion in filename.lower():\n",
    "                return emotion\n",
    "    \n",
    "    return None\n",
    "\n",
    "def extract_emotion_from_path(file_path, dataset_name):\n",
    "    \"\"\"\n",
    "    Extract emotion from file path based on dataset structure\n",
    "    \"\"\"\n",
    "    filename = os.path.basename(file_path).lower()\n",
    "    parent_dir = os.path.basename(os.path.dirname(file_path)).lower()\n",
    "    \n",
    "    emotion = None\n",
    "    \n",
    "    # 1. JL Corpus: Emotion in filename\n",
    "    if dataset_name == 'jl-corpus':\n",
    "        for target_emotion in TARGET_EMOTIONS:\n",
    "            if target_emotion in filename:\n",
    "                emotion = target_emotion\n",
    "                break\n",
    "    \n",
    "    # 2. ESD: Emotion in folder name\n",
    "    elif dataset_name == 'ESD':\n",
    "        # ESD structure: .../Angry/001/... or .../Surprise/002/...\n",
    "        for target_emotion in TARGET_EMOTIONS:\n",
    "            if target_emotion in parent_dir:\n",
    "                emotion = target_emotion\n",
    "                break\n",
    "    \n",
    "    # 3. TESS: Both folder and filename contain emotion\n",
    "    elif dataset_name == 'TESS':\n",
    "        # Check folder first (TESS has emotion folders)\n",
    "        folder_emotions = []\n",
    "        for target_emotion in TARGET_EMOTIONS:\n",
    "            if target_emotion in parent_dir:\n",
    "                folder_emotions.append(target_emotion)\n",
    "        \n",
    "        # Check filename\n",
    "        file_emotions = []\n",
    "        for target_emotion in TARGET_EMOTIONS:\n",
    "            if target_emotion in filename:\n",
    "                file_emotions.append(target_emotion)\n",
    "        \n",
    "        # Prioritize folder emotion, fallback to filename\n",
    "        if folder_emotions:\n",
    "            emotion = folder_emotions[0]\n",
    "        elif file_emotions:\n",
    "            emotion = file_emotions[0]\n",
    "        else:\n",
    "            # Check for TESS specific patterns\n",
    "            if 'ps'in filename or 'pleasant' in filename:\n",
    "                emotion = 'surprise'\n",
    "            elif 'fear' in filename or parent_dir:\n",
    "                emotion = 'surprise'\n",
    "            elif 'disgust' in filename or parent_dir:\n",
    "                emotion = 'angry' \n",
    "    \n",
    "    return emotion\n",
    "\n",
    "# =====================\n",
    "# 3. FEATURE EXTRACTION FUNCTIONS\n",
    "# =====================\n",
    "\n",
    "def extract_mfcc_features(audio_path, sr=SAMPLE_RATE, n_mfcc=N_MFCC):\n",
    "    \"\"\"\n",
    "    Extract MFCC features from audio file\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load audio\n",
    "        audio, _ = librosa.load(audio_path, sr=sr, mono=True)\n",
    "        \n",
    "        # Extract MFCC features\n",
    "        mfccs = librosa.feature.mfcc(\n",
    "            y=audio, \n",
    "            sr=sr, \n",
    "            n_mfcc=n_mfcc,\n",
    "            n_fft=N_FFT,\n",
    "            hop_length=HOP_LENGTH\n",
    "        )\n",
    "        \n",
    "        # Transpose to get (time_steps, features)\n",
    "        mfccs = mfccs.T\n",
    "        \n",
    "        # Pad/trim to fixed length (3 seconds at target sample rate)\n",
    "        target_length = int(3 * sr / HOP_LENGTH)  # ~129 frames for 3s\n",
    "        if mfccs.shape[0] > target_length:\n",
    "            mfccs = mfccs[:target_length]\n",
    "        else:\n",
    "            padding = target_length - mfccs.shape[0]\n",
    "            mfccs = np.pad(mfccs, ((0, padding), (0, 0)), mode='constant')\n",
    "        \n",
    "        return mfccs.astype(np.float32)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {audio_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# =====================\n",
    "# MODIFIED CONFIGURATION\n",
    "# =====================\n",
    "\n",
    "# ... (Keep existing imports and DATASET_PATHS) ...\n",
    "\n",
    "# Update this section for RAVDESS and SAVEE\n",
    "CSV_DATASETS = [\n",
    "    {\n",
    "        'path': 'ML - Combined Dataset (RAVDESS - SAVEE).csv',\n",
    "        'replacements': {\n",
    "            # Format: \"Prefix found in CSV\" : \"Your Local Directory Path\"\n",
    "            \n",
    "            # 1. RAVDESS Mapping\n",
    "            'ravdess-emotional-speech-audio/processed': '/Users/omari/Master Classes/ML/RAVDESS',\n",
    "            \n",
    "            # 2. SAVEE Mapping\n",
    "            'surrey-audiovisual-expressed-emotion-savee/processed': '/Users/omari/Master Classes/ML/SAVEE'\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "# =====================\n",
    "# MODIFIED CSV SCANNING FUNCTION\n",
    "# =====================\n",
    "\n",
    "def scan_csv_files(csv_configs):\n",
    "    \"\"\"\n",
    "    Scan datasets defined in CSV files with dynamic path replacement\n",
    "    \"\"\"\n",
    "    all_files = []\n",
    "    \n",
    "    for config in csv_configs:\n",
    "        csv_path = config['path']\n",
    "        replacements = config.get('replacements', {})\n",
    "        \n",
    "        if not os.path.exists(csv_path):\n",
    "            print(f\"âš ï¸ CSV file not found: {csv_path}\")\n",
    "            continue\n",
    "            \n",
    "        print(f\"\\nğŸ“„ Scanning CSV: {csv_path}...\")\n",
    "        try:\n",
    "            df = pd.read_csv(csv_path)\n",
    "            df.columns = df.columns.str.strip().str.lower()\n",
    "        except Exception as e:\n",
    "            print(f\"   âŒ Error reading CSV: {e}\")\n",
    "            continue\n",
    "            \n",
    "        required_cols = ['filepath', 'dataset', 'emotion']\n",
    "        if not all(col in df.columns for col in required_cols):\n",
    "            print(f\"   âŒ CSV missing required columns. Found: {list(df.columns)}\")\n",
    "            continue\n",
    "            \n",
    "        processed_count = 0\n",
    "        skipped_count = 0\n",
    "        missing_file_count = 0\n",
    "        \n",
    "        for _, row in tqdm(df.iterrows(), total=len(df), desc=f\"  Processing CSV\"):\n",
    "            rel_path = str(row['filepath']).strip()\n",
    "            raw_emotion = str(row['emotion']).strip()\n",
    "            dataset_name = str(row['dataset']).strip()\n",
    "            \n",
    "            # --- DYNAMIC PATH REPLACEMENT LOGIC ---\n",
    "            full_path = rel_path\n",
    "            path_replaced = False\n",
    "            \n",
    "            # Check if the CSV path starts with any of our defined prefixes\n",
    "            for prefix, replacement_dir in replacements.items():\n",
    "                # We normalize slashes to ensure matching works on Windows/Mac\n",
    "                clean_prefix = prefix.replace('\\\\', '/')\n",
    "                clean_path = rel_path.replace('\\\\', '/')\n",
    "                \n",
    "                if clean_path.startswith(clean_prefix):\n",
    "                    # Remove the prefix and join the remainder with the new local directory\n",
    "                    # This handles cases where the prefix might not have a trailing slash\n",
    "                    remainder = clean_path[len(clean_prefix):].lstrip('/')\n",
    "                    full_path = os.path.join(replacement_dir, remainder)\n",
    "                    path_replaced = True\n",
    "                    break\n",
    "            \n",
    "            # If no replacement matched, warn (optional) or treat as absolute\n",
    "            if not path_replaced and replacements:\n",
    "                # Fallback: assume the path in CSV is absolute or relative to script\n",
    "                pass\n",
    "            # --------------------------------------\n",
    "\n",
    "            # Standardize emotion\n",
    "            standardized_emotion = standardize_emotion(\n",
    "                raw_emotion, \n",
    "                os.path.basename(full_path), \n",
    "                dataset_name\n",
    "            )\n",
    "            \n",
    "            if standardized_emotion not in TARGET_EMOTIONS:\n",
    "                skipped_count += 1\n",
    "                continue\n",
    "                \n",
    "            if not os.path.exists(full_path):\n",
    "                missing_file_count += 1\n",
    "                if missing_file_count <= 3:\n",
    "                    print(f\"   âš ï¸ File not found: {full_path}\")\n",
    "                continue\n",
    "                \n",
    "            all_files.append({\n",
    "                'file_path': full_path,\n",
    "                'dataset': dataset_name,\n",
    "                'raw_emotion': raw_emotion,\n",
    "                'emotion': standardized_emotion,\n",
    "                'filename': os.path.basename(full_path)\n",
    "            })\n",
    "            processed_count += 1\n",
    "            \n",
    "        print(f\"   âœ… Processed: {processed_count}\")\n",
    "        print(f\"   âŒ Skipped (emotion): {skipped_count}\")\n",
    "        print(f\"   âš ï¸ Missing files: {missing_file_count}\")\n",
    "        \n",
    "    return all_files\n",
    "\n",
    "# =====================\n",
    "# 4. MAIN PROCESSING PIPELINE\n",
    "# =====================\n",
    "\n",
    "def create_unified_feature_file():\n",
    "    \"\"\"\n",
    "    Main function to create unified feature file\n",
    "    \"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"ğŸµ UNIFIED FEATURE EXTRACTION PIPELINE\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Step 1: Scan and categorize all files\n",
    "    print(\"\\nğŸ“Š Step 1: Scanning datasets and standardizing emotions...\")\n",
    "    \n",
    "    # A. Scan Folders (Original)\n",
    "    folder_files = scan_audio_files(DATASET_PATHS)\n",
    "    \n",
    "    # B. Scan CSVs (New Extension)\n",
    "    csv_files = scan_csv_files(CSV_DATASETS)\n",
    "    \n",
    "    # Combine lists\n",
    "    all_files = folder_files + csv_files\n",
    "    \n",
    "    if not all_files:\n",
    "        print(\"âŒ No valid audio files found!\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"\\nâœ… Total valid files: {len(all_files)}\")\n",
    "    \n",
    "    # Show emotion distribution\n",
    "    emotion_counts = {}\n",
    "    for file_info in all_files:\n",
    "        emotion = file_info['emotion']\n",
    "        emotion_counts[emotion] = emotion_counts.get(emotion, 0) + 1\n",
    "    \n",
    "    print(\"\\nğŸ“ˆ Emotion Distribution:\")\n",
    "    for emotion, count in sorted(emotion_counts.items()):\n",
    "        print(f\"  {emotion}: {count} files\")\n",
    "    \n",
    "    # Step 2: Create HDF5 file for storage\n",
    "    print(\"\\nğŸ“ Step 2: Creating unified feature file...\")\n",
    "    \n",
    "    output_file = 'unified_audio_features.h5'\n",
    "    \n",
    "    with h5py.File(output_file, 'w') as hf:\n",
    "        # Create datasets\n",
    "        features_dset = hf.create_dataset(\n",
    "            'features',\n",
    "            shape=(0, int(3 * SAMPLE_RATE / HOP_LENGTH), N_MFCC),\n",
    "            maxshape=(None, int(3 * SAMPLE_RATE / HOP_LENGTH), N_MFCC),\n",
    "            dtype=np.float32,\n",
    "            chunks=True,\n",
    "            compression='gzip'\n",
    "        )\n",
    "        \n",
    "        # Create datasets for metadata\n",
    "        emotions_dset = hf.create_dataset(\n",
    "            'emotions',\n",
    "            shape=(0,),\n",
    "            maxshape=(None,),\n",
    "            dtype=h5py.string_dtype(encoding='utf-8')\n",
    "        )\n",
    "        \n",
    "        filepaths_dset = hf.create_dataset(\n",
    "            'filepaths',\n",
    "            shape=(0,),\n",
    "            maxshape=(None,),\n",
    "            dtype=h5py.string_dtype(encoding='utf-8')\n",
    "        )\n",
    "        \n",
    "        datasets_dset = hf.create_dataset(\n",
    "            'datasets',\n",
    "            shape=(0,),\n",
    "            maxshape=(None,),\n",
    "            dtype=h5py.string_dtype(encoding='utf-8')\n",
    "        )\n",
    "        \n",
    "        # Step 3: Extract features and save\n",
    "        print(\"\\nâš¡ Step 3: Extracting MFCC features...\")\n",
    "        \n",
    "        successful = 0\n",
    "        failed = 0\n",
    "        \n",
    "        for idx, file_info in enumerate(tqdm(all_files, desc=\"Extracting features\")):\n",
    "            try:\n",
    "                # Extract features\n",
    "                features = extract_mfcc_features(file_info['file_path'])\n",
    "                \n",
    "                if features is not None:\n",
    "                    # Resize datasets\n",
    "                    features_dset.resize(features_dset.shape[0] + 1, axis=0)\n",
    "                    emotions_dset.resize(emotions_dset.shape[0] + 1, axis=0)\n",
    "                    filepaths_dset.resize(filepaths_dset.shape[0] + 1, axis=0)\n",
    "                    datasets_dset.resize(datasets_dset.shape[0] + 1, axis=0)\n",
    "                    \n",
    "                    # Add data\n",
    "                    features_dset[-1] = features\n",
    "                    emotions_dset[-1] = file_info['emotion']\n",
    "                    filepaths_dset[-1] = file_info['file_path']\n",
    "                    datasets_dset[-1] = file_info['dataset']\n",
    "                    \n",
    "                    successful += 1\n",
    "                else:\n",
    "                    failed += 1\n",
    "                    \n",
    "            except Exception as e:\n",
    "                failed += 1\n",
    "                continue\n",
    "        \n",
    "        # Save emotion encoding mapping\n",
    "        emotion_to_idx = {emotion: i for i, emotion in enumerate(TARGET_EMOTIONS)}\n",
    "        hf.attrs['emotion_encoding'] = str(emotion_to_idx)\n",
    "        hf.attrs['sample_rate'] = SAMPLE_RATE\n",
    "        hf.attrs['n_mfcc'] = N_MFCC\n",
    "        hf.attrs['total_files'] = successful\n",
    "    \n",
    "    print(f\"\\nâœ… Feature extraction complete!\")\n",
    "    print(f\"   Successful: {successful} files\")\n",
    "    print(f\"   Failed: {failed} files\")\n",
    "    print(f\"   Output file: {output_file}\")\n",
    "    print(f\"   File size: {os.path.getsize(output_file) / (1024**3):.2f} GB\")\n",
    "    \n",
    "    # Create a summary CSV for easy reference\n",
    "    print(\"\\nğŸ“‹ Creating summary CSV...\")\n",
    "    summary_data = []\n",
    "    with h5py.File(output_file, 'r') as hf:\n",
    "        for i in range(len(hf['emotions'])):\n",
    "            summary_data.append({\n",
    "                'filepath': hf['filepaths'][i].decode('utf-8'),\n",
    "                'dataset': hf['datasets'][i].decode('utf-8'),\n",
    "                'emotion': hf['emotions'][i].decode('utf-8'),\n",
    "                'feature_index': i\n",
    "            })\n",
    "    \n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "    summary_df.to_csv('features_summary.csv', index=False)\n",
    "    \n",
    "    print(f\"âœ… Summary saved to: features_summary.csv\")\n",
    "    \n",
    "    return output_file\n",
    "\n",
    "# =====================\n",
    "# 5. LOADING UTILITIES\n",
    "# =====================\n",
    "\n",
    "def load_features_from_h5(file_path, emotion_filter=None):\n",
    "    \"\"\"\n",
    "    Load features from HDF5 file with optional emotion filtering\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    labels = []\n",
    "    filepaths = []\n",
    "    \n",
    "    with h5py.File(file_path, 'r') as hf:\n",
    "        total_files = hf.attrs['total_files']\n",
    "        \n",
    "        for i in range(total_files):\n",
    "            emotion = hf['emotions'][i].decode('utf-8')\n",
    "            \n",
    "            # Apply emotion filter if specified\n",
    "            if emotion_filter and emotion not in emotion_filter:\n",
    "                continue\n",
    "            \n",
    "            features.append(hf['features'][i])\n",
    "            labels.append(emotion)\n",
    "            filepaths.append(hf['filepaths'][i].decode('utf-8'))\n",
    "    \n",
    "    return np.array(features), np.array(labels), filepaths\n",
    "\n",
    "def get_dataset_info(file_path):\n",
    "    \"\"\"\n",
    "    Get information about the stored features\n",
    "    \"\"\"\n",
    "    with h5py.File(file_path, 'r') as hf:\n",
    "        print(\"ğŸ“Š Feature File Information:\")\n",
    "        print(f\"   Total files: {hf.attrs['total_files']}\")\n",
    "        print(f\"   Sample rate: {hf.attrs['sample_rate']}\")\n",
    "        print(f\"   MFCC features: {hf.attrs['n_mfcc']}\")\n",
    "        \n",
    "        # Count emotions\n",
    "        emotions = [e.decode('utf-8') for e in hf['emotions'][:]]\n",
    "        emotion_counts = {}\n",
    "        for emotion in emotions:\n",
    "            emotion_counts[emotion] = emotion_counts.get(emotion, 0) + 1\n",
    "        \n",
    "        print(\"\\nğŸ­ Emotion Distribution:\")\n",
    "        for emotion, count in sorted(emotion_counts.items()):\n",
    "            print(f\"   {emotion}: {count} files\")\n",
    "        \n",
    "        # Show dataset distribution\n",
    "        datasets = [d.decode('utf-8') for d in hf['datasets'][:]]\n",
    "        dataset_counts = {}\n",
    "        for dataset in datasets:\n",
    "            dataset_counts[dataset] = dataset_counts.get(dataset, 0) + 1\n",
    "        \n",
    "        print(\"\\nğŸ“ Dataset Distribution:\")\n",
    "        for dataset, count in sorted(dataset_counts.items()):\n",
    "            print(f\"   {dataset}: {count} files\")\n",
    "\n",
    "# =====================\n",
    "# 6. EXECUTION\n",
    "# =====================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Run the feature extraction pipeline\n",
    "    feature_file = create_unified_feature_file()\n",
    "    \n",
    "    if feature_file:\n",
    "        # Display information about the created file\n",
    "        get_dataset_info(feature_file)\n",
    "        \n",
    "        # Example: Load all features for training\n",
    "        print(\"\\nğŸ“¥ Example: Loading features for model training...\")\n",
    "        features, labels, filepaths = load_features_from_h5(feature_file)\n",
    "        \n",
    "        print(f\"Loaded {len(features)} feature vectors\")\n",
    "        print(f\"Feature shape: {features[0].shape}\")\n",
    "        print(f\"Labels: {np.unique(labels, return_counts=True)}\")\n",
    "        \n",
    "        # Download from Colab\n",
    "        print(f\"\\nğŸ’¾ To download in Colab:\")\n",
    "        print(\"from google.colab import files\")\n",
    "        print(\"files.download('unified_audio_features.h5')\")\n",
    "        print(\"files.download('features_summary.csv')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0003848",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HYPERPARAMETER CONFIGURATION\n",
    "HYPERPARAMS = {\n",
    "    # Optimizer (Adam is most popular in SER research)\n",
    "    'optimizer': 'adam',\n",
    "    'learning_rate': 0.001,  # Most common initial LR\n",
    "    'beta_1': 0.9,           # Adam default\n",
    "    'beta_2': 0.999,         # Adam default\n",
    "    'epsilon': 1e-7,\n",
    "    \n",
    "    # Loss function (Categorical Crossentropy for multi-class)\n",
    "    'loss': 'categorical_crossentropy',\n",
    "    \n",
    "    # Metrics\n",
    "    'metrics': ['accuracy', 'categorical_accuracy'],\n",
    "    \n",
    "    # Training\n",
    "    'batch_size': 64,        # Popular: 32, 64, 128 (64 works well for 46K samples)\n",
    "    'epochs': 100,           # Use early stopping\n",
    "    \n",
    "    # Regularization\n",
    "    'l2_regularization': 0.001,  # Common weight decay\n",
    "    \n",
    "    # Learning rate scheduling\n",
    "    'lr_patience': 5,        # Reduce LR when plateau\n",
    "    'lr_factor': 0.5,        # Reduce by half\n",
    "    \n",
    "    # Early stopping\n",
    "    'early_stop_patience': 15,\n",
    "}\n",
    "\n",
    "def configure_model_for_training(model, hyperparams):\n",
    "    \"\"\"\n",
    "    Configure model with research-backed hyperparameters\n",
    "    \"\"\"\n",
    "    # Adam optimizer with recommended settings\n",
    "    optimizer = keras.optimizers.Adam(\n",
    "        learning_rate=hyperparams['learning_rate'],\n",
    "        beta_1=hyperparams['beta_1'],\n",
    "        beta_2=hyperparams['beta_2'],\n",
    "        epsilon=hyperparams['epsilon']\n",
    "    )\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=hyperparams['loss'],\n",
    "        metrics=hyperparams['metrics']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Configure the model\n",
    "model = configure_model_for_training(model, HYPERPARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8763e327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ğŸš€ STARTING BASIC CNN TRAINING (Keras 3 Compatible)\n",
      "============================================================\n",
      "ğŸ“¥ Loading your real audio features...\n",
      "   âœ… Loaded 47648 feature matrices\n",
      "   âœ… Loaded 47648 emotion labels\n",
      "   ğŸ“Š Final Data Shape: (47648, 129, 13, 1)\n",
      "\n",
      "ğŸ­ Emotion Distribution:\n",
      "   - angry: 9508\n",
      "   - happy: 9508\n",
      "   - neutral: 9472\n",
      "   - sad: 9508\n",
      "   - surprise: 9652\n",
      "\n",
      "âœ‚ï¸  Splitting data (80% Train, 20% Test)...\n",
      "   Train shape: (38118, 129, 13, 1)\n",
      "   Test shape:  (9530, 129, 13, 1)\n",
      "\n",
      "ğŸ—ï¸  Creating Basic CNN Model...\n",
      "   âœ… Using Standard Adam Optimizer (Keras 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Basic_CNN_M1_Fixed\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"Basic_CNN_M1_Fixed\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)      â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)      â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)     â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)     â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)     â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ global_average_pooling2d_1      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">325</span> â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m129\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m32\u001b[0m)    â”‚           \u001b[38;5;34m320\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2d_9 (\u001b[38;5;33mConv2D\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m129\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m32\u001b[0m)    â”‚         \u001b[38;5;34m9,248\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling2d_6 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m32\u001b[0m)      â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_10 (\u001b[38;5;33mDropout\u001b[0m)            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m32\u001b[0m)      â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2d_10 (\u001b[38;5;33mConv2D\u001b[0m)              â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)      â”‚        \u001b[38;5;34m18,496\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2d_11 (\u001b[38;5;33mConv2D\u001b[0m)              â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)      â”‚        \u001b[38;5;34m36,928\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling2d_7 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m64\u001b[0m)      â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_11 (\u001b[38;5;33mDropout\u001b[0m)            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m64\u001b[0m)      â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2d_12 (\u001b[38;5;33mConv2D\u001b[0m)              â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m128\u001b[0m)     â”‚        \u001b[38;5;34m73,856\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling2d_8 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)     â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_12 (\u001b[38;5;33mDropout\u001b[0m)            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)     â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ global_average_pooling2d_1      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚        \u001b[38;5;34m16,512\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_13 (\u001b[38;5;33mDropout\u001b[0m)            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚         \u001b[38;5;34m8,256\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_14 (\u001b[38;5;33mDropout\u001b[0m)            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              â”‚           \u001b[38;5;34m325\u001b[0m â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">163,941</span> (640.39 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m163,941\u001b[0m (640.39 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">163,941</span> (640.39 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m163,941\u001b[0m (640.39 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âš–ï¸  Calculating class weights...\n",
      "\n",
      "ğŸ”¥ Training Started...\n",
      "Epoch 1/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.2670 - loss: 1.7600\n",
      "Epoch 1: val_accuracy improved from -inf to 0.46139, saving model to basic_cnn_best_model.keras\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 90ms/step - accuracy: 0.2670 - loss: 1.7595 - val_accuracy: 0.4614 - val_loss: 1.3132 - learning_rate: 5.0000e-04\n",
      "Epoch 2/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.4143 - loss: 1.3233\n",
      "Epoch 2: val_accuracy improved from 0.46139 to 0.54974, saving model to basic_cnn_best_model.keras\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 90ms/step - accuracy: 0.4143 - loss: 1.3233 - val_accuracy: 0.5497 - val_loss: 1.0802 - learning_rate: 5.0000e-04\n",
      "Epoch 3/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 334ms/step - accuracy: 0.5044 - loss: 1.1622\n",
      "Epoch 3: val_accuracy improved from 0.54974 to 0.58447, saving model to basic_cnn_best_model.keras\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 340ms/step - accuracy: 0.5044 - loss: 1.1621 - val_accuracy: 0.5845 - val_loss: 1.0024 - learning_rate: 5.0000e-04\n",
      "Epoch 4/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.5601 - loss: 1.0458\n",
      "Epoch 4: val_accuracy improved from 0.58447 to 0.62350, saving model to basic_cnn_best_model.keras\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 90ms/step - accuracy: 0.5601 - loss: 1.0458 - val_accuracy: 0.6235 - val_loss: 0.8971 - learning_rate: 5.0000e-04\n",
      "Epoch 5/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.5990 - loss: 0.9572\n",
      "Epoch 5: val_accuracy improved from 0.62350 to 0.68751, saving model to basic_cnn_best_model.keras\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 96ms/step - accuracy: 0.5991 - loss: 0.9572 - val_accuracy: 0.6875 - val_loss: 0.7766 - learning_rate: 5.0000e-04\n",
      "Epoch 6/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.6406 - loss: 0.8829\n",
      "Epoch 6: val_accuracy improved from 0.68751 to 0.71270, saving model to basic_cnn_best_model.keras\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 93ms/step - accuracy: 0.6406 - loss: 0.8829 - val_accuracy: 0.7127 - val_loss: 0.7291 - learning_rate: 5.0000e-04\n",
      "Epoch 7/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.6688 - loss: 0.8328\n",
      "Epoch 7: val_accuracy did not improve from 0.71270\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 94ms/step - accuracy: 0.6689 - loss: 0.8328 - val_accuracy: 0.7100 - val_loss: 0.6934 - learning_rate: 5.0000e-04\n",
      "Epoch 8/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 880ms/step - accuracy: 0.6885 - loss: 0.7814\n",
      "Epoch 8: val_accuracy improved from 0.71270 to 0.74984, saving model to basic_cnn_best_model.keras\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m528s\u001b[0m 887ms/step - accuracy: 0.6885 - loss: 0.7814 - val_accuracy: 0.7498 - val_loss: 0.6275 - learning_rate: 5.0000e-04\n",
      "Epoch 9/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.7091 - loss: 0.7405\n",
      "Epoch 9: val_accuracy improved from 0.74984 to 0.75992, saving model to basic_cnn_best_model.keras\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 91ms/step - accuracy: 0.7091 - loss: 0.7405 - val_accuracy: 0.7599 - val_loss: 0.6159 - learning_rate: 5.0000e-04\n",
      "Epoch 10/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.7206 - loss: 0.7168\n",
      "Epoch 10: val_accuracy did not improve from 0.75992\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 93ms/step - accuracy: 0.7206 - loss: 0.7168 - val_accuracy: 0.7586 - val_loss: 0.6072 - learning_rate: 5.0000e-04\n",
      "Epoch 11/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 724ms/step - accuracy: 0.7398 - loss: 0.6717\n",
      "Epoch 11: val_accuracy improved from 0.75992 to 0.78730, saving model to basic_cnn_best_model.keras\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m434s\u001b[0m 730ms/step - accuracy: 0.7398 - loss: 0.6717 - val_accuracy: 0.7873 - val_loss: 0.5487 - learning_rate: 5.0000e-04\n",
      "Epoch 12/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.7469 - loss: 0.6515\n",
      "Epoch 12: val_accuracy did not improve from 0.78730\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 89ms/step - accuracy: 0.7469 - loss: 0.6516 - val_accuracy: 0.7860 - val_loss: 0.5456 - learning_rate: 5.0000e-04\n",
      "Epoch 13/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.7574 - loss: 0.6229\n",
      "Epoch 13: val_accuracy improved from 0.78730 to 0.79990, saving model to basic_cnn_best_model.keras\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 91ms/step - accuracy: 0.7575 - loss: 0.6229 - val_accuracy: 0.7999 - val_loss: 0.5172 - learning_rate: 5.0000e-04\n",
      "Epoch 14/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 519ms/step - accuracy: 0.7646 - loss: 0.6089\n",
      "Epoch 14: val_accuracy did not improve from 0.79990\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m312s\u001b[0m 524ms/step - accuracy: 0.7646 - loss: 0.6089 - val_accuracy: 0.7971 - val_loss: 0.5028 - learning_rate: 5.0000e-04\n",
      "Epoch 15/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.7716 - loss: 0.6049\n",
      "Epoch 15: val_accuracy did not improve from 0.79990\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 89ms/step - accuracy: 0.7716 - loss: 0.6049 - val_accuracy: 0.7933 - val_loss: 0.5138 - learning_rate: 5.0000e-04\n",
      "Epoch 16/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.7741 - loss: 0.5865\n",
      "Epoch 16: val_accuracy improved from 0.79990 to 0.80493, saving model to basic_cnn_best_model.keras\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 92ms/step - accuracy: 0.7741 - loss: 0.5865 - val_accuracy: 0.8049 - val_loss: 0.4842 - learning_rate: 5.0000e-04\n",
      "Epoch 17/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - accuracy: 0.7855 - loss: 0.5639\n",
      "Epoch 17: val_accuracy improved from 0.80493 to 0.81102, saving model to basic_cnn_best_model.keras\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 171ms/step - accuracy: 0.7855 - loss: 0.5639 - val_accuracy: 0.8110 - val_loss: 0.4970 - learning_rate: 5.0000e-04\n",
      "Epoch 18/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.7814 - loss: 0.5715\n",
      "Epoch 18: val_accuracy did not improve from 0.81102\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 94ms/step - accuracy: 0.7814 - loss: 0.5715 - val_accuracy: 0.8107 - val_loss: 0.4643 - learning_rate: 5.0000e-04\n",
      "Epoch 19/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.7959 - loss: 0.5402\n",
      "Epoch 19: val_accuracy improved from 0.81102 to 0.81952, saving model to basic_cnn_best_model.keras\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 96ms/step - accuracy: 0.7959 - loss: 0.5402 - val_accuracy: 0.8195 - val_loss: 0.4668 - learning_rate: 5.0000e-04\n",
      "Epoch 20/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.7979 - loss: 0.5286\n",
      "Epoch 20: val_accuracy improved from 0.81952 to 0.82508, saving model to basic_cnn_best_model.keras\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 96ms/step - accuracy: 0.7979 - loss: 0.5286 - val_accuracy: 0.8251 - val_loss: 0.4616 - learning_rate: 5.0000e-04\n",
      "Epoch 21/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.8008 - loss: 0.5227\n",
      "Epoch 21: val_accuracy did not improve from 0.82508\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 95ms/step - accuracy: 0.8008 - loss: 0.5227 - val_accuracy: 0.8169 - val_loss: 0.4655 - learning_rate: 5.0000e-04\n",
      "Epoch 22/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.8029 - loss: 0.5150\n",
      "Epoch 22: val_accuracy improved from 0.82508 to 0.82529, saving model to basic_cnn_best_model.keras\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 95ms/step - accuracy: 0.8029 - loss: 0.5150 - val_accuracy: 0.8253 - val_loss: 0.4398 - learning_rate: 5.0000e-04\n",
      "Epoch 23/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.8054 - loss: 0.5186\n",
      "Epoch 23: val_accuracy did not improve from 0.82529\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 97ms/step - accuracy: 0.8054 - loss: 0.5186 - val_accuracy: 0.8151 - val_loss: 0.4772 - learning_rate: 5.0000e-04\n",
      "Epoch 24/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.8082 - loss: 0.5142\n",
      "Epoch 24: val_accuracy improved from 0.82529 to 0.83295, saving model to basic_cnn_best_model.keras\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 97ms/step - accuracy: 0.8082 - loss: 0.5142 - val_accuracy: 0.8329 - val_loss: 0.4236 - learning_rate: 5.0000e-04\n",
      "Epoch 25/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.8079 - loss: 0.4948\n",
      "Epoch 25: val_accuracy improved from 0.83295 to 0.83557, saving model to basic_cnn_best_model.keras\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 97ms/step - accuracy: 0.8079 - loss: 0.4948 - val_accuracy: 0.8356 - val_loss: 0.4350 - learning_rate: 5.0000e-04\n",
      "Epoch 26/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.8187 - loss: 0.4858\n",
      "Epoch 26: val_accuracy did not improve from 0.83557\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 96ms/step - accuracy: 0.8187 - loss: 0.4858 - val_accuracy: 0.8303 - val_loss: 0.4198 - learning_rate: 5.0000e-04\n",
      "Epoch 27/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.8195 - loss: 0.4723\n",
      "Epoch 27: val_accuracy improved from 0.83557 to 0.83966, saving model to basic_cnn_best_model.keras\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 96ms/step - accuracy: 0.8195 - loss: 0.4723 - val_accuracy: 0.8397 - val_loss: 0.4172 - learning_rate: 5.0000e-04\n",
      "Epoch 28/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.8191 - loss: 0.4828\n",
      "Epoch 28: val_accuracy improved from 0.83966 to 0.84092, saving model to basic_cnn_best_model.keras\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 99ms/step - accuracy: 0.8191 - loss: 0.4828 - val_accuracy: 0.8409 - val_loss: 0.4020 - learning_rate: 5.0000e-04\n",
      "Epoch 29/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.8221 - loss: 0.4679\n",
      "Epoch 29: val_accuracy did not improve from 0.84092\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 98ms/step - accuracy: 0.8221 - loss: 0.4679 - val_accuracy: 0.8261 - val_loss: 0.4496 - learning_rate: 5.0000e-04\n",
      "Epoch 30/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.8229 - loss: 0.4617\n",
      "Epoch 30: val_accuracy improved from 0.84092 to 0.84302, saving model to basic_cnn_best_model.keras\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 98ms/step - accuracy: 0.8229 - loss: 0.4617 - val_accuracy: 0.8430 - val_loss: 0.4016 - learning_rate: 5.0000e-04\n",
      "Epoch 31/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.8280 - loss: 0.4602\n",
      "Epoch 31: val_accuracy did not improve from 0.84302\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 99ms/step - accuracy: 0.8280 - loss: 0.4602 - val_accuracy: 0.8242 - val_loss: 0.4459 - learning_rate: 5.0000e-04\n",
      "Epoch 32/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.8279 - loss: 0.4597\n",
      "Epoch 32: val_accuracy did not improve from 0.84302\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 98ms/step - accuracy: 0.8279 - loss: 0.4597 - val_accuracy: 0.8333 - val_loss: 0.4352 - learning_rate: 5.0000e-04\n",
      "Epoch 33/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.8329 - loss: 0.4410\n",
      "Epoch 33: val_accuracy did not improve from 0.84302\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 99ms/step - accuracy: 0.8329 - loss: 0.4410 - val_accuracy: 0.8377 - val_loss: 0.4170 - learning_rate: 5.0000e-04\n",
      "Epoch 34/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.8296 - loss: 0.4471\n",
      "Epoch 34: val_accuracy did not improve from 0.84302\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 99ms/step - accuracy: 0.8296 - loss: 0.4471 - val_accuracy: 0.8421 - val_loss: 0.4134 - learning_rate: 5.0000e-04\n",
      "Epoch 35/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.8348 - loss: 0.4395\n",
      "Epoch 35: val_accuracy improved from 0.84302 to 0.84848, saving model to basic_cnn_best_model.keras\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 98ms/step - accuracy: 0.8348 - loss: 0.4395 - val_accuracy: 0.8485 - val_loss: 0.3898 - learning_rate: 5.0000e-04\n",
      "Epoch 36/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 0.8331 - loss: 0.4439\n",
      "Epoch 36: val_accuracy improved from 0.84848 to 0.85037, saving model to basic_cnn_best_model.keras\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 154ms/step - accuracy: 0.8331 - loss: 0.4439 - val_accuracy: 0.8504 - val_loss: 0.3979 - learning_rate: 5.0000e-04\n",
      "Epoch 37/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.8357 - loss: 0.4360\n",
      "Epoch 37: val_accuracy did not improve from 0.85037\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 95ms/step - accuracy: 0.8357 - loss: 0.4360 - val_accuracy: 0.8470 - val_loss: 0.3975 - learning_rate: 5.0000e-04\n",
      "Epoch 38/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.8392 - loss: 0.4241\n",
      "Epoch 38: val_accuracy did not improve from 0.85037\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 96ms/step - accuracy: 0.8392 - loss: 0.4241 - val_accuracy: 0.8492 - val_loss: 0.3893 - learning_rate: 5.0000e-04\n",
      "Epoch 39/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.8373 - loss: 0.4262\n",
      "Epoch 39: val_accuracy did not improve from 0.85037\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 98ms/step - accuracy: 0.8373 - loss: 0.4262 - val_accuracy: 0.8490 - val_loss: 0.4004 - learning_rate: 5.0000e-04\n",
      "Epoch 40/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.8415 - loss: 0.4266\n",
      "Epoch 40: val_accuracy improved from 0.85037 to 0.85163, saving model to basic_cnn_best_model.keras\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 98ms/step - accuracy: 0.8415 - loss: 0.4266 - val_accuracy: 0.8516 - val_loss: 0.3878 - learning_rate: 5.0000e-04\n",
      "Epoch 41/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.8365 - loss: 0.4256\n",
      "Epoch 41: val_accuracy did not improve from 0.85163\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 98ms/step - accuracy: 0.8365 - loss: 0.4256 - val_accuracy: 0.8475 - val_loss: 0.3869 - learning_rate: 5.0000e-04\n",
      "Epoch 42/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.8443 - loss: 0.4237\n",
      "Epoch 42: val_accuracy did not improve from 0.85163\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 98ms/step - accuracy: 0.8443 - loss: 0.4237 - val_accuracy: 0.8490 - val_loss: 0.3945 - learning_rate: 5.0000e-04\n",
      "Epoch 43/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.8464 - loss: 0.4063\n",
      "Epoch 43: val_accuracy did not improve from 0.85163\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 97ms/step - accuracy: 0.8464 - loss: 0.4063 - val_accuracy: 0.8505 - val_loss: 0.3863 - learning_rate: 5.0000e-04\n",
      "Epoch 44/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.8536 - loss: 0.3966\n",
      "Epoch 44: val_accuracy did not improve from 0.85163\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 95ms/step - accuracy: 0.8536 - loss: 0.3966 - val_accuracy: 0.8507 - val_loss: 0.3793 - learning_rate: 5.0000e-04\n",
      "Epoch 45/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12s/step - accuracy: 0.8497 - loss: 0.4024 \n",
      "Epoch 45: val_accuracy improved from 0.85163 to 0.85289, saving model to basic_cnn_best_model.keras\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7210s\u001b[0m 12s/step - accuracy: 0.8497 - loss: 0.4024 - val_accuracy: 0.8529 - val_loss: 0.3869 - learning_rate: 5.0000e-04\n",
      "Epoch 46/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8s/step - accuracy: 0.8524 - loss: 0.3936\n",
      "Epoch 46: val_accuracy improved from 0.85289 to 0.85981, saving model to basic_cnn_best_model.keras\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5781s\u001b[0m 10s/step - accuracy: 0.8524 - loss: 0.3936 - val_accuracy: 0.8598 - val_loss: 0.3687 - learning_rate: 5.0000e-04\n",
      "Epoch 47/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9s/step - accuracy: 0.8496 - loss: 0.3989\n",
      "Epoch 47: val_accuracy improved from 0.85981 to 0.86118, saving model to basic_cnn_best_model.keras\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5177s\u001b[0m 9s/step - accuracy: 0.8496 - loss: 0.3989 - val_accuracy: 0.8612 - val_loss: 0.3656 - learning_rate: 5.0000e-04\n",
      "Epoch 48/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6s/step - accuracy: 0.8526 - loss: 0.3999\n",
      "Epoch 48: val_accuracy did not improve from 0.86118\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3695s\u001b[0m 6s/step - accuracy: 0.8526 - loss: 0.3999 - val_accuracy: 0.8422 - val_loss: 0.4130 - learning_rate: 5.0000e-04\n",
      "Epoch 49/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11s/step - accuracy: 0.8503 - loss: 0.3962 \n",
      "Epoch 49: val_accuracy did not improve from 0.86118\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6684s\u001b[0m 11s/step - accuracy: 0.8503 - loss: 0.3963 - val_accuracy: 0.8567 - val_loss: 0.3708 - learning_rate: 5.0000e-04\n",
      "Epoch 50/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8s/step - accuracy: 0.8529 - loss: 0.3924\n",
      "Epoch 50: val_accuracy improved from 0.86118 to 0.86180, saving model to basic_cnn_best_model.keras\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4868s\u001b[0m 8s/step - accuracy: 0.8529 - loss: 0.3924 - val_accuracy: 0.8618 - val_loss: 0.3687 - learning_rate: 5.0000e-04\n",
      "Epoch 51/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 0.8560 - loss: 0.3831\n",
      "Epoch 51: val_accuracy did not improve from 0.86180\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 109ms/step - accuracy: 0.8560 - loss: 0.3831 - val_accuracy: 0.8541 - val_loss: 0.3709 - learning_rate: 5.0000e-04\n",
      "Epoch 52/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.8579 - loss: 0.3816\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 52: val_accuracy did not improve from 0.86180\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 98ms/step - accuracy: 0.8579 - loss: 0.3816 - val_accuracy: 0.8615 - val_loss: 0.3707 - learning_rate: 5.0000e-04\n",
      "Epoch 53/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - accuracy: 0.8704 - loss: 0.3490\n",
      "Epoch 53: val_accuracy improved from 0.86180 to 0.86600, saving model to basic_cnn_best_model.keras\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 208ms/step - accuracy: 0.8704 - loss: 0.3490 - val_accuracy: 0.8660 - val_loss: 0.3526 - learning_rate: 2.5000e-04\n",
      "Epoch 54/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.8698 - loss: 0.3491\n",
      "Epoch 54: val_accuracy improved from 0.86600 to 0.86768, saving model to basic_cnn_best_model.keras\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 90ms/step - accuracy: 0.8699 - loss: 0.3491 - val_accuracy: 0.8677 - val_loss: 0.3542 - learning_rate: 2.5000e-04\n",
      "Epoch 55/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.8742 - loss: 0.3399\n",
      "Epoch 55: val_accuracy improved from 0.86768 to 0.87104, saving model to basic_cnn_best_model.keras\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 91ms/step - accuracy: 0.8742 - loss: 0.3399 - val_accuracy: 0.8710 - val_loss: 0.3473 - learning_rate: 2.5000e-04\n",
      "Epoch 56/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.8728 - loss: 0.3379\n",
      "Epoch 56: val_accuracy did not improve from 0.87104\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 99ms/step - accuracy: 0.8728 - loss: 0.3379 - val_accuracy: 0.8692 - val_loss: 0.3484 - learning_rate: 2.5000e-04\n",
      "Epoch 57/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.8752 - loss: 0.3379\n",
      "Epoch 57: val_accuracy improved from 0.87104 to 0.87503, saving model to basic_cnn_best_model.keras\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 100ms/step - accuracy: 0.8752 - loss: 0.3379 - val_accuracy: 0.8750 - val_loss: 0.3404 - learning_rate: 2.5000e-04\n",
      "Epoch 58/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.8785 - loss: 0.3258\n",
      "Epoch 58: val_accuracy did not improve from 0.87503\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 96ms/step - accuracy: 0.8785 - loss: 0.3258 - val_accuracy: 0.8699 - val_loss: 0.3460 - learning_rate: 2.5000e-04\n",
      "Epoch 59/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.8780 - loss: 0.3253\n",
      "Epoch 59: val_accuracy did not improve from 0.87503\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 97ms/step - accuracy: 0.8780 - loss: 0.3253 - val_accuracy: 0.8683 - val_loss: 0.3506 - learning_rate: 2.5000e-04\n",
      "Epoch 60/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - accuracy: 0.8785 - loss: 0.3251\n",
      "Epoch 60: val_accuracy did not improve from 0.87503\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 106ms/step - accuracy: 0.8785 - loss: 0.3251 - val_accuracy: 0.8720 - val_loss: 0.3315 - learning_rate: 2.5000e-04\n",
      "Epoch 61/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - accuracy: 0.8800 - loss: 0.3236\n",
      "Epoch 61: val_accuracy did not improve from 0.87503\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 111ms/step - accuracy: 0.8800 - loss: 0.3236 - val_accuracy: 0.8722 - val_loss: 0.3329 - learning_rate: 2.5000e-04\n",
      "Epoch 62/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 0.8809 - loss: 0.3237\n",
      "Epoch 62: val_accuracy did not improve from 0.87503\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 103ms/step - accuracy: 0.8809 - loss: 0.3237 - val_accuracy: 0.8701 - val_loss: 0.3400 - learning_rate: 2.5000e-04\n",
      "Epoch 63/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.8791 - loss: 0.3247\n",
      "Epoch 63: val_accuracy did not improve from 0.87503\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 102ms/step - accuracy: 0.8791 - loss: 0.3247 - val_accuracy: 0.8709 - val_loss: 0.3438 - learning_rate: 2.5000e-04\n",
      "Epoch 64/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 0.8796 - loss: 0.3184\n",
      "Epoch 64: val_accuracy did not improve from 0.87503\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 105ms/step - accuracy: 0.8796 - loss: 0.3184 - val_accuracy: 0.8715 - val_loss: 0.3357 - learning_rate: 2.5000e-04\n",
      "Epoch 65/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.8795 - loss: 0.3245\n",
      "Epoch 65: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 65: val_accuracy did not improve from 0.87503\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 100ms/step - accuracy: 0.8795 - loss: 0.3245 - val_accuracy: 0.8733 - val_loss: 0.3374 - learning_rate: 2.5000e-04\n",
      "Epoch 66/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.8875 - loss: 0.3075\n",
      "Epoch 66: val_accuracy improved from 0.87503 to 0.87912, saving model to basic_cnn_best_model.keras\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 96ms/step - accuracy: 0.8875 - loss: 0.3075 - val_accuracy: 0.8791 - val_loss: 0.3210 - learning_rate: 1.2500e-04\n",
      "Epoch 67/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 0.8879 - loss: 0.2986\n",
      "Epoch 67: val_accuracy did not improve from 0.87912\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 102ms/step - accuracy: 0.8879 - loss: 0.2987 - val_accuracy: 0.8778 - val_loss: 0.3339 - learning_rate: 1.2500e-04\n",
      "Epoch 68/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - accuracy: 0.8906 - loss: 0.2987\n",
      "Epoch 68: val_accuracy improved from 0.87912 to 0.87985, saving model to basic_cnn_best_model.keras\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 111ms/step - accuracy: 0.8906 - loss: 0.2987 - val_accuracy: 0.8799 - val_loss: 0.3195 - learning_rate: 1.2500e-04\n",
      "Epoch 69/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - accuracy: 0.8906 - loss: 0.2933\n",
      "Epoch 69: val_accuracy improved from 0.87985 to 0.88048, saving model to basic_cnn_best_model.keras\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 106ms/step - accuracy: 0.8906 - loss: 0.2933 - val_accuracy: 0.8805 - val_loss: 0.3250 - learning_rate: 1.2500e-04\n",
      "Epoch 70/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 0.8913 - loss: 0.2908\n",
      "Epoch 70: val_accuracy did not improve from 0.88048\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 104ms/step - accuracy: 0.8913 - loss: 0.2908 - val_accuracy: 0.8721 - val_loss: 0.3399 - learning_rate: 1.2500e-04\n",
      "Epoch 71/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - accuracy: 0.8935 - loss: 0.2902\n",
      "Epoch 71: val_accuracy improved from 0.88048 to 0.88059, saving model to basic_cnn_best_model.keras\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 105ms/step - accuracy: 0.8935 - loss: 0.2902 - val_accuracy: 0.8806 - val_loss: 0.3238 - learning_rate: 1.2500e-04\n",
      "Epoch 72/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.8922 - loss: 0.2905\n",
      "Epoch 72: val_accuracy did not improve from 0.88059\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 95ms/step - accuracy: 0.8922 - loss: 0.2905 - val_accuracy: 0.8785 - val_loss: 0.3301 - learning_rate: 1.2500e-04\n",
      "Epoch 73/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.8931 - loss: 0.2866\n",
      "Epoch 73: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 73: val_accuracy improved from 0.88059 to 0.88143, saving model to basic_cnn_best_model.keras\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 97ms/step - accuracy: 0.8931 - loss: 0.2866 - val_accuracy: 0.8814 - val_loss: 0.3233 - learning_rate: 1.2500e-04\n",
      "Epoch 74/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - accuracy: 0.8936 - loss: 0.2849\n",
      "Epoch 74: val_accuracy improved from 0.88143 to 0.88174, saving model to basic_cnn_best_model.keras\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 106ms/step - accuracy: 0.8936 - loss: 0.2849 - val_accuracy: 0.8817 - val_loss: 0.3247 - learning_rate: 6.2500e-05\n",
      "Epoch 75/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 0.8995 - loss: 0.2755\n",
      "Epoch 75: val_accuracy did not improve from 0.88174\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 104ms/step - accuracy: 0.8995 - loss: 0.2755 - val_accuracy: 0.8814 - val_loss: 0.3248 - learning_rate: 6.2500e-05\n",
      "Epoch 76/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.8980 - loss: 0.2797\n",
      "Epoch 76: val_accuracy improved from 0.88174 to 0.88195, saving model to basic_cnn_best_model.keras\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 100ms/step - accuracy: 0.8980 - loss: 0.2797 - val_accuracy: 0.8820 - val_loss: 0.3251 - learning_rate: 6.2500e-05\n",
      "Epoch 77/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 0.8982 - loss: 0.2757\n",
      "Epoch 77: val_accuracy improved from 0.88195 to 0.88300, saving model to basic_cnn_best_model.keras\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 104ms/step - accuracy: 0.8982 - loss: 0.2757 - val_accuracy: 0.8830 - val_loss: 0.3241 - learning_rate: 6.2500e-05\n",
      "Epoch 78/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.8994 - loss: 0.2705\n",
      "Epoch 78: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 78: val_accuracy did not improve from 0.88300\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 102ms/step - accuracy: 0.8994 - loss: 0.2705 - val_accuracy: 0.8772 - val_loss: 0.3331 - learning_rate: 6.2500e-05\n",
      "Epoch 79/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.8986 - loss: 0.2685\n",
      "Epoch 79: val_accuracy did not improve from 0.88300\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 100ms/step - accuracy: 0.8986 - loss: 0.2685 - val_accuracy: 0.8821 - val_loss: 0.3226 - learning_rate: 3.1250e-05\n",
      "Epoch 80/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.9003 - loss: 0.2676\n",
      "Epoch 80: val_accuracy did not improve from 0.88300\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 100ms/step - accuracy: 0.9003 - loss: 0.2676 - val_accuracy: 0.8797 - val_loss: 0.3295 - learning_rate: 3.1250e-05\n",
      "Restoring model weights from the end of the best epoch: 77.\n",
      "\n",
      "========================================\n",
      "ğŸ“Š FINAL EVALUATION\n",
      "========================================\n",
      "ğŸ“¥ Loading best saved model...\n",
      "âš¡ Generating predictions on Test Set...\n",
      "\u001b[1m298/298\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step\n",
      "\n",
      "âœ… Overall Accuracy:  0.8830 (88.30%)\n",
      "âœ… Weighted Precision: 0.8830\n",
      "âœ… Weighted Recall:    0.8830\n",
      "âœ… Weighted F1-Score:  0.8829\n",
      "\n",
      "ğŸ“‹ CLASSIFICATION REPORT\n",
      "------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.89      0.87      0.88      1902\n",
      "       happy       0.83      0.83      0.83      1902\n",
      "     neutral       0.90      0.91      0.91      1894\n",
      "         sad       0.90      0.93      0.92      1902\n",
      "    surprise       0.89      0.86      0.88      1930\n",
      "\n",
      "    accuracy                           0.88      9530\n",
      "   macro avg       0.88      0.88      0.88      9530\n",
      "weighted avg       0.88      0.88      0.88      9530\n",
      "\n",
      "\n",
      "ğŸ“‰ CONFUSION MATRIX\n",
      "------------------------------------------------------------\n",
      "[[1664  113   39   26   60]\n",
      " [  99 1588   44   41  130]\n",
      " [  21   32 1731  108    2]\n",
      " [   7   27   96 1767    5]\n",
      " [  81  159   11   14 1665]]\n",
      "\n",
      "ğŸ’¾ Predictions saved to 'basic_cnn_predictions.csv'\n",
      "\n",
      "ğŸ“ˆ Plotting History...\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# =====================\n",
    "# FIXED BASIC CNN TRAINING PIPELINE (Keras 3 + Mac M1/M2 Compatible)\n",
    "# =====================\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    classification_report, confusion_matrix\n",
    ")\n",
    "\n",
    "# =====================\n",
    "# 1. LOAD DATA\n",
    "# =====================\n",
    "\n",
    "def load_real_data(features_file='unified_audio_features.h5'):\n",
    "    \"\"\"\n",
    "    Load actual MFCC features and labels from H5 file\n",
    "    \"\"\"\n",
    "    print(\"ğŸ“¥ Loading your real audio features...\")\n",
    "    \n",
    "    if not os.path.exists(features_file):\n",
    "        raise FileNotFoundError(f\"âŒ File {features_file} not found! Please run feature extraction first.\")\n",
    "\n",
    "    with h5py.File(features_file, 'r') as hf:\n",
    "        # Load features\n",
    "        features = hf['features'][:]\n",
    "        print(f\"   âœ… Loaded {len(features)} feature matrices\")\n",
    "        \n",
    "        # Load emotions\n",
    "        emotions = [e.decode('utf-8') for e in hf['emotions'][:]]\n",
    "        print(f\"   âœ… Loaded {len(emotions)} emotion labels\")\n",
    "        \n",
    "        # Load filepaths\n",
    "        filepaths = [f.decode('utf-8') for f in hf['filepaths'][:]]\n",
    "    \n",
    "    # CNN REQUIREMENT: Shape must be (Batch, Height, Width, Channels)\n",
    "    # Current: (46424, 129, 13)\n",
    "    # Target:  (46424, 129, 13, 1)\n",
    "    features = np.expand_dims(features, axis=-1)\n",
    "    print(f\"   ğŸ“Š Final Data Shape: {features.shape}\")\n",
    "    \n",
    "    # Encode emotions\n",
    "    label_encoder = LabelEncoder()\n",
    "    emotion_labels = label_encoder.fit_transform(emotions)\n",
    "    onehot_labels = keras.utils.to_categorical(emotion_labels, 5)\n",
    "    \n",
    "    # Print Distribution\n",
    "    print(f\"\\nğŸ­ Emotion Distribution:\")\n",
    "    unique, counts = np.unique(emotions, return_counts=True)\n",
    "    for emotion, count in zip(unique, counts):\n",
    "        print(f\"   - {emotion}: {count}\")\n",
    "    \n",
    "    return features, onehot_labels, label_encoder, filepaths\n",
    "\n",
    "# =====================\n",
    "# 2. DEFINE BASIC CNN MODEL (M1 FIXED)\n",
    "# =====================\n",
    "\n",
    "def create_basic_cnn_model(input_shape, num_classes):\n",
    "    \"\"\"\n",
    "    Basic CNN Architecture adjusted for Mac M1/M2 stability.\n",
    "    REMOVED BatchNormalization layers to fix 'Incompatible shapes' error.\n",
    "    INCREASED Dropout to compensate for lack of BN regularization.\n",
    "    \"\"\"\n",
    "    model = keras.Sequential(name=\"Basic_CNN_M1_Fixed\")\n",
    "    \n",
    "    model.add(layers.Input(shape=input_shape))\n",
    "    \n",
    "    # --- Conv Block 1 ---\n",
    "    model.add(layers.Conv2D(32, (3, 3), padding='same', activation='relu'))\n",
    "    # BatchNormalization REMOVED\n",
    "    model.add(layers.Conv2D(32, (3, 3), padding='same', activation='relu'))\n",
    "    # BatchNormalization REMOVED\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Dropout(0.25))  # Increased from 0.15\n",
    "    \n",
    "    # --- Conv Block 2 ---\n",
    "    model.add(layers.Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "    # BatchNormalization REMOVED\n",
    "    model.add(layers.Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "    # BatchNormalization REMOVED\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Dropout(0.3))   # Increased from 0.2\n",
    "    \n",
    "    # --- Conv Block 3 (Optional extra depth) ---\n",
    "    model.add(layers.Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
    "    # BatchNormalization REMOVED\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    \n",
    "    # --- Global Pooling ---\n",
    "    model.add(layers.GlobalAveragePooling2D())\n",
    "    \n",
    "    # --- Dense Layers ---\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    # BatchNormalization REMOVED\n",
    "    model.add(layers.Dropout(0.4))   # Increased from 0.3\n",
    "    \n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dropout(0.4))\n",
    "    \n",
    "    # --- Output ---\n",
    "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "# =====================\n",
    "# 3. MAIN TRAINING PIPELINE\n",
    "# =====================\n",
    "\n",
    "def run_training_pipeline():\n",
    "    print(\"=\" * 60)\n",
    "    print(\"ğŸš€ STARTING BASIC CNN TRAINING (Keras 3 Compatible)\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # 1. Load Data\n",
    "    try:\n",
    "        X, y, label_encoder, filepaths = load_real_data()\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Critical Error: {e}\")\n",
    "        return\n",
    "\n",
    "    # 2. Split Data (Stratified)\n",
    "    print(\"\\nâœ‚ï¸  Splitting data (80% Train, 20% Test)...\")\n",
    "    y_integers = np.argmax(y, axis=1)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, \n",
    "        test_size=0.2, \n",
    "        random_state=42, \n",
    "        stratify=y_integers\n",
    "    )\n",
    "    print(f\"   Train shape: {X_train.shape}\")\n",
    "    print(f\"   Test shape:  {X_test.shape}\")\n",
    "    \n",
    "    # 3. Create Model\n",
    "    print(\"\\nğŸ—ï¸  Creating Basic CNN Model...\")\n",
    "    model = create_basic_cnn_model(input_shape=X_train.shape[1:], num_classes=5)\n",
    "    \n",
    "    # OPTIMIZER FIX: Use standard Adam (legacy is removed in Keras 3)\n",
    "    # Since we removed BatchNormalization, standard Adam is safe on M1.\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=0.0005)\n",
    "    print(\"   âœ… Using Standard Adam Optimizer (Keras 3)\")\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    model.summary()\n",
    "    \n",
    "    # 4. Class Weights\n",
    "    print(\"\\nâš–ï¸  Calculating class weights...\")\n",
    "    train_labels_int = np.argmax(y_train, axis=1)\n",
    "    class_weights = compute_class_weight(\n",
    "        'balanced', \n",
    "        classes=np.unique(train_labels_int), \n",
    "        y=train_labels_int\n",
    "    )\n",
    "    class_weight_dict = dict(enumerate(class_weights))\n",
    "    \n",
    "    # 5. Callbacks\n",
    "    callbacks = [\n",
    "        keras.callbacks.EarlyStopping(\n",
    "            monitor='val_accuracy', patience=12, restore_best_weights=True, verbose=1\n",
    "        ),\n",
    "        keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6, verbose=1\n",
    "        ),\n",
    "        keras.callbacks.ModelCheckpoint(\n",
    "            'basic_cnn_best_model.keras', monitor='val_accuracy', save_best_only=True, verbose=1\n",
    "        ),\n",
    "        keras.callbacks.CSVLogger('training_history_cnn.csv')\n",
    "    ]\n",
    "    \n",
    "    # 6. Train\n",
    "    print(\"\\nğŸ”¥ Training Started...\")\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_test, y_test),\n",
    "        epochs=80,\n",
    "        batch_size=64,\n",
    "        callbacks=callbacks,\n",
    "        class_weight=class_weight_dict,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # =====================\n",
    "    # 4. FINAL EVALUATION\n",
    "    # =====================\n",
    "    print(\"\\n\" + \"=\"*40)\n",
    "    print(\"ğŸ“Š FINAL EVALUATION\")\n",
    "    print(\"=\"*40)\n",
    "    \n",
    "    # Load Best Model\n",
    "    print(\"ğŸ“¥ Loading best saved model...\")\n",
    "    best_model = keras.models.load_model('basic_cnn_best_model.keras')\n",
    "    \n",
    "    # Get Predictions\n",
    "    print(\"âš¡ Generating predictions on Test Set...\")\n",
    "    y_pred_probs = best_model.predict(X_test, verbose=1)\n",
    "    y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "    y_true = np.argmax(y_test, axis=1)\n",
    "    \n",
    "    # Calculate Metrics\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred, average='weighted')\n",
    "    rec = recall_score(y_true, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "    \n",
    "    print(f\"\\nâœ… Overall Accuracy:  {acc:.4f} ({acc*100:.2f}%)\")\n",
    "    print(f\"âœ… Weighted Precision: {prec:.4f}\")\n",
    "    print(f\"âœ… Weighted Recall:    {rec:.4f}\")\n",
    "    print(f\"âœ… Weighted F1-Score:  {f1:.4f}\")\n",
    "    \n",
    "    print(\"\\nğŸ“‹ CLASSIFICATION REPORT\")\n",
    "    print(\"-\" * 60)\n",
    "    print(classification_report(y_true, y_pred, target_names=label_encoder.classes_))\n",
    "    \n",
    "    print(\"\\nğŸ“‰ CONFUSION MATRIX\")\n",
    "    print(\"-\" * 60)\n",
    "    print(confusion_matrix(y_true, y_pred))\n",
    "    \n",
    "    # Save Results\n",
    "    results_df = pd.DataFrame({\n",
    "        'filepath': [filepaths[i] for i in range(len(X_test))],\n",
    "        'true_emotion': label_encoder.inverse_transform(y_true),\n",
    "        'predicted_emotion': label_encoder.inverse_transform(y_pred),\n",
    "        'confidence': np.max(y_pred_probs, axis=1)\n",
    "    })\n",
    "    results_df.to_csv('basic_cnn_predictions.csv', index=False)\n",
    "    print(f\"\\nğŸ’¾ Predictions saved to 'basic_cnn_predictions.csv'\")\n",
    "\n",
    "    # Plot History\n",
    "    print(\"\\nğŸ“ˆ Plotting History...\")\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'], label='Train Acc')\n",
    "    plt.plot(history.history['val_accuracy'], label='Val Acc')\n",
    "    plt.title('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'], label='Train Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "    plt.title('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('cnn_training_history.png')\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_training_pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f76fa7d",
   "metadata": {},
   "source": [
    "### CRNN (CNN + LSTM layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282728bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ğŸµ TRAINING CRNN (CNN + LSTM) ON REAL DATA\n",
      "============================================================\n",
      "ğŸ“¥ Loading your real audio features...\n",
      "âœ… Loaded 47648 feature matrices\n",
      "âœ… Loaded 47648 emotion labels\n",
      "\n",
      "ğŸ“Š Data Shapes:\n",
      "  Features: (47648, 129, 13)\n",
      "  After adding channel: (47648, 129, 13, 1)\n",
      "\n",
      "ğŸ­ Emotion Distribution:\n",
      "  angry: 9508 samples\n",
      "  happy: 9508 samples\n",
      "  neutral: 9472 samples\n",
      "  sad: 9508 samples\n",
      "  surprise: 9652 samples\n",
      "\n",
      "ğŸ“Š Step 2: Splitting data (80% train, 20% test)...\n",
      "\n",
      "ğŸ—ï¸  Step 3: Creating CRNN model...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)     â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_1           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)     â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)     â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)     â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)     â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_2           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)     â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)     â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)     â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ time_distributed                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">197,120</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_3           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">325</span> â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m129\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m64\u001b[0m)    â”‚           \u001b[38;5;34m640\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m129\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m64\u001b[0m)    â”‚           \u001b[38;5;34m256\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)      â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout (\u001b[38;5;33mDropout\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)      â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m128\u001b[0m)     â”‚        \u001b[38;5;34m73,856\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_1           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m128\u001b[0m)     â”‚           \u001b[38;5;34m512\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m128\u001b[0m)     â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m128\u001b[0m)     â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m256\u001b[0m)     â”‚       \u001b[38;5;34m295,168\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_2           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m256\u001b[0m)     â”‚         \u001b[38;5;34m1,024\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)     â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)     â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ time_distributed                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m256\u001b[0m)        â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mTimeDistributed\u001b[0m)               â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚       \u001b[38;5;34m197,120\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense (\u001b[38;5;33mDense\u001b[0m)                   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚         \u001b[38;5;34m8,256\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_3           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚           \u001b[38;5;34m256\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              â”‚           \u001b[38;5;34m325\u001b[0m â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">577,413</span> (2.20 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m577,413\u001b[0m (2.20 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">576,389</span> (2.20 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m576,389\u001b[0m (2.20 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> (4.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,024\u001b[0m (4.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âš–ï¸  Step 4: Calculating class weights...\n",
      "\n",
      "ğŸš€ Step 6: Training CRNN...\n",
      "Epoch 1/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 0.3232 - loss: 1.6907\n",
      "Epoch 1: val_accuracy improved from -inf to 0.47156, saving model to crnn_best_model.keras\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 160ms/step - accuracy: 0.3233 - loss: 1.6904 - val_accuracy: 0.4716 - val_loss: 1.2342 - learning_rate: 5.0000e-04\n",
      "Epoch 2/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - accuracy: 0.4717 - loss: 1.2430\n",
      "Epoch 2: val_accuracy improved from 0.47156 to 0.54460, saving model to crnn_best_model.keras\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 163ms/step - accuracy: 0.4718 - loss: 1.2429 - val_accuracy: 0.5446 - val_loss: 1.0803 - learning_rate: 5.0000e-04\n",
      "Epoch 3/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - accuracy: 0.5671 - loss: 1.0455\n",
      "Epoch 3: val_accuracy improved from 0.54460 to 0.64701, saving model to crnn_best_model.keras\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 164ms/step - accuracy: 0.5671 - loss: 1.0454 - val_accuracy: 0.6470 - val_loss: 0.8624 - learning_rate: 5.0000e-04\n",
      "Epoch 4/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 0.6393 - loss: 0.9008\n",
      "Epoch 4: val_accuracy improved from 0.64701 to 0.66327, saving model to crnn_best_model.keras\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 161ms/step - accuracy: 0.6393 - loss: 0.9008 - val_accuracy: 0.6633 - val_loss: 0.8065 - learning_rate: 5.0000e-04\n",
      "Epoch 5/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 613ms/step - accuracy: 0.6855 - loss: 0.7911\n",
      "Epoch 5: val_accuracy improved from 0.66327 to 0.74900, saving model to crnn_best_model.keras\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m370s\u001b[0m 622ms/step - accuracy: 0.6855 - loss: 0.7910 - val_accuracy: 0.7490 - val_loss: 0.6533 - learning_rate: 5.0000e-04\n",
      "Epoch 6/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 0.7359 - loss: 0.7008\n",
      "Epoch 6: val_accuracy improved from 0.74900 to 0.76516, saving model to crnn_best_model.keras\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 152ms/step - accuracy: 0.7358 - loss: 0.7008 - val_accuracy: 0.7652 - val_loss: 0.6106 - learning_rate: 5.0000e-04\n",
      "Epoch 7/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.7595 - loss: 0.6324\n",
      "Epoch 7: val_accuracy improved from 0.76516 to 0.77817, saving model to crnn_best_model.keras\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1688s\u001b[0m 3s/step - accuracy: 0.7595 - loss: 0.6324 - val_accuracy: 0.7782 - val_loss: 0.5773 - learning_rate: 5.0000e-04\n",
      "Epoch 8/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 0.7810 - loss: 0.5768\n",
      "Epoch 8: val_accuracy improved from 0.77817 to 0.80766, saving model to crnn_best_model.keras\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 156ms/step - accuracy: 0.7810 - loss: 0.5768 - val_accuracy: 0.8077 - val_loss: 0.5023 - learning_rate: 5.0000e-04\n",
      "Epoch 9/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 0.8026 - loss: 0.5297\n",
      "Epoch 9: val_accuracy did not improve from 0.80766\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 154ms/step - accuracy: 0.8026 - loss: 0.5297 - val_accuracy: 0.7801 - val_loss: 0.5992 - learning_rate: 5.0000e-04\n",
      "Epoch 10/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 0.8112 - loss: 0.5131\n",
      "Epoch 10: val_accuracy improved from 0.80766 to 0.82592, saving model to crnn_best_model.keras\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 157ms/step - accuracy: 0.8112 - loss: 0.5131 - val_accuracy: 0.8259 - val_loss: 0.4605 - learning_rate: 5.0000e-04\n",
      "Epoch 11/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 0.8280 - loss: 0.4635\n",
      "Epoch 11: val_accuracy improved from 0.82592 to 0.83421, saving model to crnn_best_model.keras\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 158ms/step - accuracy: 0.8280 - loss: 0.4635 - val_accuracy: 0.8342 - val_loss: 0.4359 - learning_rate: 5.0000e-04\n",
      "Epoch 12/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 0.8408 - loss: 0.4340\n",
      "Epoch 12: val_accuracy improved from 0.83421 to 0.83788, saving model to crnn_best_model.keras\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 158ms/step - accuracy: 0.8408 - loss: 0.4340 - val_accuracy: 0.8379 - val_loss: 0.4310 - learning_rate: 5.0000e-04\n",
      "Epoch 13/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - accuracy: 0.8478 - loss: 0.4087\n",
      "Epoch 13: val_accuracy improved from 0.83788 to 0.85677, saving model to crnn_best_model.keras\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 161ms/step - accuracy: 0.8478 - loss: 0.4087 - val_accuracy: 0.8568 - val_loss: 0.3749 - learning_rate: 5.0000e-04\n",
      "Epoch 14/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - accuracy: 0.8609 - loss: 0.3747\n",
      "Epoch 14: val_accuracy improved from 0.85677 to 0.86128, saving model to crnn_best_model.keras\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 172ms/step - accuracy: 0.8609 - loss: 0.3747 - val_accuracy: 0.8613 - val_loss: 0.3772 - learning_rate: 5.0000e-04\n",
      "Epoch 15/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - accuracy: 0.8684 - loss: 0.3608\n",
      "Epoch 15: val_accuracy did not improve from 0.86128\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 163ms/step - accuracy: 0.8684 - loss: 0.3608 - val_accuracy: 0.8570 - val_loss: 0.3882 - learning_rate: 5.0000e-04\n",
      "Epoch 16/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 0.8728 - loss: 0.3500\n",
      "Epoch 16: val_accuracy improved from 0.86128 to 0.86758, saving model to crnn_best_model.keras\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 162ms/step - accuracy: 0.8728 - loss: 0.3500 - val_accuracy: 0.8676 - val_loss: 0.3780 - learning_rate: 5.0000e-04\n",
      "Epoch 17/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 0.8850 - loss: 0.3168\n",
      "Epoch 17: val_accuracy did not improve from 0.86758\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 166ms/step - accuracy: 0.8850 - loss: 0.3168 - val_accuracy: 0.8568 - val_loss: 0.4120 - learning_rate: 5.0000e-04\n",
      "Epoch 18/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - accuracy: 0.8912 - loss: 0.2968\n",
      "Epoch 18: val_accuracy improved from 0.86758 to 0.87356, saving model to crnn_best_model.keras\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m230s\u001b[0m 387ms/step - accuracy: 0.8912 - loss: 0.2968 - val_accuracy: 0.8736 - val_loss: 0.3552 - learning_rate: 5.0000e-04\n",
      "Epoch 19/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 0.8923 - loss: 0.2941\n",
      "Epoch 19: val_accuracy improved from 0.87356 to 0.87471, saving model to crnn_best_model.keras\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 158ms/step - accuracy: 0.8923 - loss: 0.2942 - val_accuracy: 0.8747 - val_loss: 0.3580 - learning_rate: 5.0000e-04\n",
      "Epoch 20/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 0.9025 - loss: 0.2752\n",
      "Epoch 20: val_accuracy did not improve from 0.87471\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 160ms/step - accuracy: 0.9025 - loss: 0.2752 - val_accuracy: 0.8582 - val_loss: 0.4046 - learning_rate: 5.0000e-04\n",
      "Epoch 21/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262ms/step - accuracy: 0.9027 - loss: 0.2688\n",
      "Epoch 21: val_accuracy did not improve from 0.87471\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 272ms/step - accuracy: 0.9027 - loss: 0.2688 - val_accuracy: 0.8499 - val_loss: 0.4293 - learning_rate: 5.0000e-04\n",
      "Epoch 22/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 0.9071 - loss: 0.2592\n",
      "Epoch 22: val_accuracy improved from 0.87471 to 0.88437, saving model to crnn_best_model.keras\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 166ms/step - accuracy: 0.9071 - loss: 0.2592 - val_accuracy: 0.8844 - val_loss: 0.3279 - learning_rate: 5.0000e-04\n",
      "Epoch 23/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - accuracy: 0.9145 - loss: 0.2364\n",
      "Epoch 23: val_accuracy did not improve from 0.88437\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 160ms/step - accuracy: 0.9145 - loss: 0.2364 - val_accuracy: 0.8760 - val_loss: 0.3465 - learning_rate: 5.0000e-04\n",
      "Epoch 24/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 0.9163 - loss: 0.2361\n",
      "Epoch 24: val_accuracy improved from 0.88437 to 0.88478, saving model to crnn_best_model.keras\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 159ms/step - accuracy: 0.9163 - loss: 0.2361 - val_accuracy: 0.8848 - val_loss: 0.3363 - learning_rate: 5.0000e-04\n",
      "Epoch 25/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - accuracy: 0.9244 - loss: 0.2121\n",
      "Epoch 25: val_accuracy improved from 0.88478 to 0.88583, saving model to crnn_best_model.keras\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 163ms/step - accuracy: 0.9244 - loss: 0.2121 - val_accuracy: 0.8858 - val_loss: 0.3271 - learning_rate: 5.0000e-04\n",
      "Epoch 26/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - accuracy: 0.9217 - loss: 0.2143\n",
      "Epoch 26: val_accuracy did not improve from 0.88583\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 164ms/step - accuracy: 0.9217 - loss: 0.2143 - val_accuracy: 0.8706 - val_loss: 0.3877 - learning_rate: 5.0000e-04\n",
      "Epoch 27/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 0.9249 - loss: 0.2083\n",
      "Epoch 27: val_accuracy improved from 0.88583 to 0.89255, saving model to crnn_best_model.keras\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 161ms/step - accuracy: 0.9249 - loss: 0.2083 - val_accuracy: 0.8925 - val_loss: 0.3128 - learning_rate: 5.0000e-04\n",
      "Epoch 28/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - accuracy: 0.9311 - loss: 0.1936\n",
      "Epoch 28: val_accuracy did not improve from 0.89255\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 210ms/step - accuracy: 0.9311 - loss: 0.1936 - val_accuracy: 0.8867 - val_loss: 0.3431 - learning_rate: 5.0000e-04\n",
      "Epoch 29/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 430ms/step - accuracy: 0.9325 - loss: 0.1920\n",
      "Epoch 29: val_accuracy did not improve from 0.89255\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 438ms/step - accuracy: 0.9325 - loss: 0.1920 - val_accuracy: 0.8845 - val_loss: 0.3410 - learning_rate: 5.0000e-04\n",
      "Epoch 30/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 0.9377 - loss: 0.1718\n",
      "Epoch 30: val_accuracy improved from 0.89255 to 0.89465, saving model to crnn_best_model.keras\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 157ms/step - accuracy: 0.9377 - loss: 0.1718 - val_accuracy: 0.8946 - val_loss: 0.3107 - learning_rate: 5.0000e-04\n",
      "Epoch 31/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 0.9362 - loss: 0.1775\n",
      "Epoch 31: val_accuracy did not improve from 0.89465\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 159ms/step - accuracy: 0.9362 - loss: 0.1775 - val_accuracy: 0.8940 - val_loss: 0.3345 - learning_rate: 5.0000e-04\n",
      "Epoch 32/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 0.9419 - loss: 0.1665\n",
      "Epoch 32: val_accuracy did not improve from 0.89465\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 161ms/step - accuracy: 0.9419 - loss: 0.1665 - val_accuracy: 0.8927 - val_loss: 0.3254 - learning_rate: 5.0000e-04\n",
      "Epoch 33/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - accuracy: 0.9404 - loss: 0.1703\n",
      "Epoch 33: val_accuracy did not improve from 0.89465\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 162ms/step - accuracy: 0.9404 - loss: 0.1703 - val_accuracy: 0.8913 - val_loss: 0.3506 - learning_rate: 5.0000e-04\n",
      "Epoch 34/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - accuracy: 0.9469 - loss: 0.1550\n",
      "Epoch 34: val_accuracy did not improve from 0.89465\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 163ms/step - accuracy: 0.9469 - loss: 0.1550 - val_accuracy: 0.8894 - val_loss: 0.3243 - learning_rate: 5.0000e-04\n",
      "Epoch 35/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - accuracy: 0.9472 - loss: 0.1522\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 35: val_accuracy did not improve from 0.89465\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 210ms/step - accuracy: 0.9472 - loss: 0.1522 - val_accuracy: 0.8841 - val_loss: 0.3644 - learning_rate: 5.0000e-04\n",
      "Epoch 36/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9550 - loss: 0.1248\n",
      "Epoch 36: val_accuracy improved from 0.89465 to 0.90241, saving model to crnn_best_model.keras\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m998s\u001b[0m 2s/step - accuracy: 0.9550 - loss: 0.1248 - val_accuracy: 0.9024 - val_loss: 0.3115 - learning_rate: 2.5000e-04\n",
      "Epoch 37/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9616 - loss: 0.1084\n",
      "Epoch 37: val_accuracy did not improve from 0.90241\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1116s\u001b[0m 2s/step - accuracy: 0.9616 - loss: 0.1084 - val_accuracy: 0.8993 - val_loss: 0.3273 - learning_rate: 2.5000e-04\n",
      "Epoch 38/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9637 - loss: 0.1076\n",
      "Epoch 38: val_accuracy did not improve from 0.90241\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m992s\u001b[0m 2s/step - accuracy: 0.9637 - loss: 0.1076 - val_accuracy: 0.9014 - val_loss: 0.3256 - learning_rate: 2.5000e-04\n",
      "Epoch 39/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9654 - loss: 0.0999\n",
      "Epoch 39: val_accuracy improved from 0.90241 to 0.90357, saving model to crnn_best_model.keras\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m993s\u001b[0m 2s/step - accuracy: 0.9654 - loss: 0.0999 - val_accuracy: 0.9036 - val_loss: 0.3192 - learning_rate: 2.5000e-04\n",
      "Epoch 40/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 0.9683 - loss: 0.0927\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\n",
      "Epoch 40: val_accuracy did not improve from 0.90357\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 159ms/step - accuracy: 0.9683 - loss: 0.0927 - val_accuracy: 0.9035 - val_loss: 0.3226 - learning_rate: 2.5000e-04\n",
      "Epoch 41/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - accuracy: 0.9713 - loss: 0.0827\n",
      "Epoch 41: val_accuracy improved from 0.90357 to 0.90745, saving model to crnn_best_model.keras\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 164ms/step - accuracy: 0.9713 - loss: 0.0827 - val_accuracy: 0.9075 - val_loss: 0.3123 - learning_rate: 1.2500e-04\n",
      "Epoch 42/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 0.9743 - loss: 0.0765\n",
      "Epoch 42: val_accuracy improved from 0.90745 to 0.90965, saving model to crnn_best_model.keras\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 167ms/step - accuracy: 0.9743 - loss: 0.0765 - val_accuracy: 0.9097 - val_loss: 0.3233 - learning_rate: 1.2500e-04\n",
      "Epoch 43/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 0.9763 - loss: 0.0703\n",
      "Epoch 43: val_accuracy did not improve from 0.90965\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 168ms/step - accuracy: 0.9763 - loss: 0.0703 - val_accuracy: 0.9077 - val_loss: 0.3382 - learning_rate: 1.2500e-04\n",
      "Epoch 44/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - accuracy: 0.9766 - loss: 0.0675\n",
      "Epoch 44: val_accuracy improved from 0.90965 to 0.91112, saving model to crnn_best_model.keras\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 170ms/step - accuracy: 0.9766 - loss: 0.0675 - val_accuracy: 0.9111 - val_loss: 0.3289 - learning_rate: 1.2500e-04\n",
      "Epoch 45/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 0.9767 - loss: 0.0684\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\n",
      "Epoch 45: val_accuracy did not improve from 0.91112\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 168ms/step - accuracy: 0.9767 - loss: 0.0684 - val_accuracy: 0.9081 - val_loss: 0.3287 - learning_rate: 1.2500e-04\n",
      "Epoch 46/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - accuracy: 0.9794 - loss: 0.0622\n",
      "Epoch 46: val_accuracy did not improve from 0.91112\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 163ms/step - accuracy: 0.9794 - loss: 0.0622 - val_accuracy: 0.9109 - val_loss: 0.3252 - learning_rate: 6.2500e-05\n",
      "Epoch 47/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - accuracy: 0.9804 - loss: 0.0580\n",
      "Epoch 47: val_accuracy did not improve from 0.91112\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 164ms/step - accuracy: 0.9804 - loss: 0.0580 - val_accuracy: 0.9103 - val_loss: 0.3302 - learning_rate: 6.2500e-05\n",
      "Epoch 48/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - accuracy: 0.9812 - loss: 0.0590\n",
      "Epoch 48: val_accuracy did not improve from 0.91112\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 163ms/step - accuracy: 0.9812 - loss: 0.0590 - val_accuracy: 0.9104 - val_loss: 0.3325 - learning_rate: 6.2500e-05\n",
      "Epoch 49/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - accuracy: 0.9800 - loss: 0.0618\n",
      "Epoch 49: val_accuracy did not improve from 0.91112\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 165ms/step - accuracy: 0.9800 - loss: 0.0618 - val_accuracy: 0.9084 - val_loss: 0.3490 - learning_rate: 6.2500e-05\n",
      "Epoch 50/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - accuracy: 0.9822 - loss: 0.0543\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\n",
      "Epoch 50: val_accuracy did not improve from 0.91112\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 164ms/step - accuracy: 0.9822 - loss: 0.0543 - val_accuracy: 0.9095 - val_loss: 0.3401 - learning_rate: 6.2500e-05\n",
      "Epoch 51/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - accuracy: 0.9823 - loss: 0.0544\n",
      "Epoch 51: val_accuracy improved from 0.91112 to 0.91322, saving model to crnn_best_model.keras\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 164ms/step - accuracy: 0.9823 - loss: 0.0544 - val_accuracy: 0.9132 - val_loss: 0.3262 - learning_rate: 3.1250e-05\n",
      "Epoch 52/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 0.9831 - loss: 0.0510\n",
      "Epoch 52: val_accuracy did not improve from 0.91322\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 167ms/step - accuracy: 0.9831 - loss: 0.0510 - val_accuracy: 0.9126 - val_loss: 0.3327 - learning_rate: 3.1250e-05\n",
      "Epoch 53/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - accuracy: 0.9831 - loss: 0.0484\n",
      "Epoch 53: val_accuracy improved from 0.91322 to 0.91333, saving model to crnn_best_model.keras\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 178ms/step - accuracy: 0.9831 - loss: 0.0484 - val_accuracy: 0.9133 - val_loss: 0.3348 - learning_rate: 3.1250e-05\n",
      "Epoch 54/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - accuracy: 0.9830 - loss: 0.0497\n",
      "Epoch 54: val_accuracy did not improve from 0.91333\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 181ms/step - accuracy: 0.9829 - loss: 0.0497 - val_accuracy: 0.9129 - val_loss: 0.3339 - learning_rate: 3.1250e-05\n",
      "Epoch 55/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - accuracy: 0.9845 - loss: 0.0465\n",
      "Epoch 55: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\n",
      "Epoch 55: val_accuracy did not improve from 0.91333\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 180ms/step - accuracy: 0.9845 - loss: 0.0465 - val_accuracy: 0.9119 - val_loss: 0.3369 - learning_rate: 3.1250e-05\n",
      "Epoch 56/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - accuracy: 0.9839 - loss: 0.0459\n",
      "Epoch 56: val_accuracy improved from 0.91333 to 0.91364, saving model to crnn_best_model.keras\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 181ms/step - accuracy: 0.9839 - loss: 0.0459 - val_accuracy: 0.9136 - val_loss: 0.3366 - learning_rate: 1.5625e-05\n",
      "Epoch 57/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - accuracy: 0.9849 - loss: 0.0461\n",
      "Epoch 57: val_accuracy improved from 0.91364 to 0.91532, saving model to crnn_best_model.keras\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 181ms/step - accuracy: 0.9849 - loss: 0.0461 - val_accuracy: 0.9153 - val_loss: 0.3366 - learning_rate: 1.5625e-05\n",
      "Epoch 58/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - accuracy: 0.9840 - loss: 0.0472\n",
      "Epoch 58: val_accuracy did not improve from 0.91532\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 181ms/step - accuracy: 0.9840 - loss: 0.0472 - val_accuracy: 0.9153 - val_loss: 0.3373 - learning_rate: 1.5625e-05\n",
      "Epoch 59/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - accuracy: 0.9836 - loss: 0.0486\n",
      "Epoch 59: val_accuracy did not improve from 0.91532\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 182ms/step - accuracy: 0.9836 - loss: 0.0486 - val_accuracy: 0.9132 - val_loss: 0.3376 - learning_rate: 1.5625e-05\n",
      "Epoch 60/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - accuracy: 0.9848 - loss: 0.0455\n",
      "Epoch 60: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\n",
      "Epoch 60: val_accuracy did not improve from 0.91532\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 182ms/step - accuracy: 0.9848 - loss: 0.0455 - val_accuracy: 0.9134 - val_loss: 0.3368 - learning_rate: 1.5625e-05\n",
      "Epoch 61/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - accuracy: 0.9841 - loss: 0.0466\n",
      "Epoch 61: val_accuracy did not improve from 0.91532\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 182ms/step - accuracy: 0.9841 - loss: 0.0466 - val_accuracy: 0.9133 - val_loss: 0.3372 - learning_rate: 7.8125e-06\n",
      "Epoch 62/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - accuracy: 0.9842 - loss: 0.0476\n",
      "Epoch 62: val_accuracy did not improve from 0.91532\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 183ms/step - accuracy: 0.9842 - loss: 0.0476 - val_accuracy: 0.9143 - val_loss: 0.3357 - learning_rate: 7.8125e-06\n",
      "Epoch 63/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - accuracy: 0.9847 - loss: 0.0458\n",
      "Epoch 63: val_accuracy did not improve from 0.91532\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 185ms/step - accuracy: 0.9847 - loss: 0.0458 - val_accuracy: 0.9137 - val_loss: 0.3367 - learning_rate: 7.8125e-06\n",
      "Epoch 64/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - accuracy: 0.9832 - loss: 0.0490\n",
      "Epoch 64: val_accuracy did not improve from 0.91532\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m111s\u001b[0m 186ms/step - accuracy: 0.9832 - loss: 0.0490 - val_accuracy: 0.9149 - val_loss: 0.3391 - learning_rate: 7.8125e-06\n",
      "Epoch 65/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - accuracy: 0.9846 - loss: 0.0473\n",
      "Epoch 65: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\n",
      "Epoch 65: val_accuracy did not improve from 0.91532\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 184ms/step - accuracy: 0.9846 - loss: 0.0473 - val_accuracy: 0.9148 - val_loss: 0.3406 - learning_rate: 7.8125e-06\n",
      "Epoch 66/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 0.9843 - loss: 0.0451\n",
      "Epoch 66: val_accuracy did not improve from 0.91532\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 157ms/step - accuracy: 0.9843 - loss: 0.0451 - val_accuracy: 0.9146 - val_loss: 0.3380 - learning_rate: 3.9063e-06\n",
      "Epoch 67/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9s/step - accuracy: 0.9847 - loss: 0.0465\n",
      "Epoch 67: val_accuracy did not improve from 0.91532\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5467s\u001b[0m 9s/step - accuracy: 0.9847 - loss: 0.0465 - val_accuracy: 0.9145 - val_loss: 0.3384 - learning_rate: 3.9063e-06\n",
      "Epoch 68/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - accuracy: 0.9851 - loss: 0.0451\n",
      "Epoch 68: val_accuracy did not improve from 0.91532\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1874s\u001b[0m 3s/step - accuracy: 0.9851 - loss: 0.0451 - val_accuracy: 0.9148 - val_loss: 0.3381 - learning_rate: 3.9063e-06\n",
      "Epoch 69/80\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12s/step - accuracy: 0.9856 - loss: 0.0421 \n",
      "Epoch 69: val_accuracy did not improve from 0.91532\n",
      "\u001b[1m596/596\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7292s\u001b[0m 12s/step - accuracy: 0.9856 - loss: 0.0421 - val_accuracy: 0.9153 - val_loss: 0.3390 - learning_rate: 3.9063e-06\n",
      "Epoch 69: early stopping\n",
      "Restoring model weights from the end of the best epoch: 57.\n",
      "\n",
      "ğŸ“Š Step 7: Evaluating final model...\n",
      "   Test Accuracy: 0.9153\n",
      "\n",
      "ğŸ’¾ Step 8: Saving predictions...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'DataFrame'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 217\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m best_model, history\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m     \u001b[43mtrain_on_real_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[20], line 191\u001b[0m, in \u001b[0;36mtrain_on_real_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m    188\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(best_model\u001b[38;5;241m.\u001b[39mpredict(X_test, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    189\u001b[0m y_true \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(y_test, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 191\u001b[0m results_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m({\n\u001b[1;32m    192\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrue_emotion\u001b[39m\u001b[38;5;124m'\u001b[39m: label_encoder\u001b[38;5;241m.\u001b[39minverse_transform(y_true),\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredicted_emotion\u001b[39m\u001b[38;5;124m'\u001b[39m: label_encoder\u001b[38;5;241m.\u001b[39minverse_transform(y_pred)\n\u001b[1;32m    194\u001b[0m })\n\u001b[1;32m    195\u001b[0m results_df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcrnn_predictions.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# 9. Plot History\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'DataFrame'"
     ]
    }
   ],
   "source": [
    "# =====================\n",
    "# CRNN TRAINING PIPELINE FOR SER\n",
    "# =====================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# =====================\n",
    "# 1. LOAD DATA\n",
    "# =====================\n",
    "\n",
    "def load_real_data(features_file='unified_audio_features.h5'):\n",
    "    \"\"\"\n",
    "    Load your actual 46K MFCC features and labels\n",
    "    \"\"\"\n",
    "    print(\"ğŸ“¥ Loading your real audio features...\")\n",
    "    \n",
    "    with h5py.File(features_file, 'r') as hf:\n",
    "        # Load features\n",
    "        features = hf['features'][:]\n",
    "        print(f\"âœ… Loaded {len(features)} feature matrices\")\n",
    "        \n",
    "        # Load emotions\n",
    "        emotions = [e.decode('utf-8') for e in hf['emotions'][:]]\n",
    "        print(f\"âœ… Loaded {len(emotions)} emotion labels\")\n",
    "        \n",
    "        # Load filepaths for reference\n",
    "        filepaths = [f.decode('utf-8') for f in hf['filepaths'][:]]\n",
    "        \n",
    "        # Check shapes\n",
    "        # Expected shape from H5: (N_samples, TimeSteps, N_MFCC) e.g., (46424, 129, 13)\n",
    "        print(f\"\\nğŸ“Š Data Shapes:\")\n",
    "        print(f\"  Features: {features.shape}\") \n",
    "    \n",
    "    # CRNN requires shape: (Batch, Time, Features, Channels)\n",
    "    # The 'Time' dimension must be preserved for LSTM. \n",
    "    # Current: (N, 129, 13) -> Add channel: (N, 129, 13, 1)\n",
    "    features = np.expand_dims(features, axis=-1)\n",
    "    print(f\"  After adding channel: {features.shape}\")\n",
    "    \n",
    "    # Encode emotions\n",
    "    label_encoder = LabelEncoder()\n",
    "    emotion_labels = label_encoder.fit_transform(emotions)\n",
    "    \n",
    "    # One-hot encoding\n",
    "    onehot_labels = keras.utils.to_categorical(emotion_labels, 5)\n",
    "    \n",
    "    print(f\"\\nğŸ­ Emotion Distribution:\")\n",
    "    unique, counts = np.unique(emotions, return_counts=True)\n",
    "    for emotion, count in zip(unique, counts):\n",
    "        print(f\"  {emotion}: {count} samples\")\n",
    "    \n",
    "    return features, onehot_labels, label_encoder, filepaths\n",
    "\n",
    "# =====================\n",
    "# 2. CREATE CRNN MODEL\n",
    "# =====================\n",
    "\n",
    "def create_crnn_model(input_shape, num_classes):\n",
    "    \"\"\"\n",
    "    Creates a CRNN (Convolutional Recurrent Neural Network)\n",
    "    CNN extracts spatial features from MFCCs\n",
    "    LSTM captures temporal context of those features\n",
    "    \"\"\"\n",
    "    model = keras.Sequential()\n",
    "    \n",
    "    # --- CNN BLOCK (Feature Extractor) ---\n",
    "    # Input Shape: (129, 13, 1) -> (Time, Freq, Channel)\n",
    "    \n",
    "    # Conv Block 1\n",
    "    model.add(layers.Conv2D(64, (3, 3), padding='same', activation='relu', input_shape=input_shape))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    # Pool only Frequency axis (axis 2), preserve Time (axis 1) slightly\n",
    "    # (2, 1) means downsample Time by 2, Frequency by 1 (keep frequency resolution high)\n",
    "    # OR standard (2,2) to reduce both. Let's use (2,2) for standard reduction.\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2))) \n",
    "    model.add(layers.Dropout(0.2))\n",
    "    \n",
    "    # Conv Block 2\n",
    "    model.add(layers.Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "    \n",
    "    # Conv Block 3\n",
    "    model.add(layers.Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "\n",
    "    # --- RECURRENT BLOCK (Temporal Context) ---\n",
    "    \n",
    "    # Current Shape: (Batch, Reduced_Time, Reduced_Freq, Filters)\n",
    "    # We need to reshape for LSTM: (Batch, Time, Features)\n",
    "    \n",
    "    # TimeDistributed(Flatten) collapses (Freq * Filters) into one vector per time step\n",
    "    model.add(layers.TimeDistributed(layers.Flatten()))\n",
    "    \n",
    "    # LSTM Layer\n",
    "    # Returns only the final state (return_sequences=False) for classification\n",
    "    model.add(layers.LSTM(128, return_sequences=False))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    \n",
    "    # --- CLASSIFICATION BLOCK ---\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    \n",
    "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "# =====================\n",
    "# 3. TRAINING PIPELINE\n",
    "# =====================\n",
    "\n",
    "def train_on_real_data():\n",
    "    print(\"=\" * 60)\n",
    "    print(\"ğŸµ TRAINING CRNN (CNN + LSTM) ON REAL DATA\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # 1. Load Data\n",
    "    X, y, label_encoder, filepaths = load_real_data()\n",
    "    \n",
    "    # 2. Split Data\n",
    "    print(\"\\nğŸ“Š Step 2: Splitting data (80% train, 20% test)...\")\n",
    "    y_integers = np.argmax(y, axis=1)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y_integers\n",
    "    )\n",
    "    \n",
    "    # 3. Create CRNN Model \n",
    "    print(\"\\nğŸ—ï¸  Step 3: Creating CRNN model...\")\n",
    "    model = create_crnn_model(input_shape=X_train.shape[1:], num_classes=5)\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=0.0005),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    # 4. Class Weights\n",
    "    print(\"\\nâš–ï¸  Step 4: Calculating class weights...\")\n",
    "    train_labels_int = np.argmax(y_train, axis=1)\n",
    "    class_weights = compute_class_weight('balanced', classes=np.unique(train_labels_int), y=train_labels_int)\n",
    "    class_weight_dict = dict(enumerate(class_weights))\n",
    "    \n",
    "    # 5. Callbacks\n",
    "    callbacks = [\n",
    "        keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=12, restore_best_weights=True, verbose=1),\n",
    "        keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6, verbose=1),\n",
    "        keras.callbacks.ModelCheckpoint('crnn_best_model.keras', monitor='val_accuracy', save_best_only=True, verbose=1),\n",
    "        keras.callbacks.CSVLogger('training_history_crnn.csv')\n",
    "    ]\n",
    "    \n",
    "    # 6. Train\n",
    "    print(\"\\nğŸš€ Step 6: Training CRNN...\")\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_test, y_test),\n",
    "        epochs=80,  # CRNNs might converge faster or need fewer epochs than pure CNNs\n",
    "        batch_size=64,\n",
    "        callbacks=callbacks,\n",
    "        class_weight=class_weight_dict,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # 7. Evaluate\n",
    "    print(\"\\nğŸ“Š Step 7: Evaluating final model...\")\n",
    "    best_model = keras.models.load_model('crnn_best_model.keras')\n",
    "    test_loss, test_acc = best_model.evaluate(X_test, y_test, verbose=0)\n",
    "    print(f\"   Test Accuracy: {test_acc:.4f}\")\n",
    "    \n",
    "    # 8. Save Predictions\n",
    "    print(\"\\nğŸ’¾ Step 8: Saving predictions...\")\n",
    "    y_pred = np.argmax(best_model.predict(X_test, verbose=0), axis=1)\n",
    "    y_true = np.argmax(y_test, axis=1)\n",
    "    \n",
    "    results_df = pd.DataFrame({\n",
    "        'true_emotion': label_encoder.inverse_transform(y_true),\n",
    "        'predicted_emotion': label_encoder.inverse_transform(y_pred)\n",
    "    })\n",
    "    results_df.to_csv('crnn_predictions.csv', index=False)\n",
    "    \n",
    "    # 9. Plot History\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'], label='Train')\n",
    "    plt.plot(history.history['val_accuracy'], label='Val')\n",
    "    plt.title('CRNN Accuracy')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'], label='Train')\n",
    "    plt.plot(history.history['val_loss'], label='Val')\n",
    "    plt.title('CRNN Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.savefig('crnn_training_plot.png')\n",
    "    plt.show()\n",
    "    \n",
    "    return best_model, history\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_on_real_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a3c44d9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ Resuming pipeline from Evaluation Phase (Skipping Training)...\n",
      "âœ… Data reloaded. Test set size: 9530\n",
      "ğŸ“¥ Loading saved model...\n",
      "\n",
      "ğŸ“Š Evaluating model performance...\n",
      "\u001b[1m298/298\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - accuracy: 0.9144 - loss: 0.3386\n",
      "   Final Test Accuracy: 0.9153\n",
      "\n",
      "ğŸ’¾ Generating predictions CSV...\n",
      "âœ… Saved to 'crnn_predictions.csv'\n",
      "\n",
      "ğŸ“ˆ Plotting training history from logs...\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Plot saved to 'crnn_training_plot.png'\n"
     ]
    }
   ],
   "source": [
    "# =====================\n",
    "# CONTINUATION SCRIPT (NO RETRAINING)\n",
    "# =====================\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd  # <--- Correct import\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "\n",
    "# Re-define the load function needed to get X_test/y_test back\n",
    "def load_real_data(features_file='unified_audio_features.h5'):\n",
    "    with h5py.File(features_file, 'r') as hf:\n",
    "        features = hf['features'][:]\n",
    "        emotions = [e.decode('utf-8') for e in hf['emotions'][:]]\n",
    "    \n",
    "    # Expand dims for channel\n",
    "    features = np.expand_dims(features, axis=-1)\n",
    "    \n",
    "    # Re-encode labels\n",
    "    label_encoder = LabelEncoder()\n",
    "    emotion_labels = label_encoder.fit_transform(emotions)\n",
    "    onehot_labels = keras.utils.to_categorical(emotion_labels, 5)\n",
    "    \n",
    "    return features, onehot_labels, label_encoder\n",
    "\n",
    "def continue_evaluation_only():\n",
    "    print(\"ğŸ”„ Resuming pipeline from Evaluation Phase (Skipping Training)...\")\n",
    "    \n",
    "    # 1. Reload Data (Fast)\n",
    "    # We need X_test and y_test to be exactly the same as during training\n",
    "    # So we use the SAME random_state=42\n",
    "    X, y, label_encoder = load_real_data()\n",
    "    \n",
    "    y_integers = np.argmax(y, axis=1)\n",
    "    _, X_test, _, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y_integers\n",
    "    )\n",
    "    print(f\"âœ… Data reloaded. Test set size: {len(X_test)}\")\n",
    "\n",
    "    # 2. Load the Best Saved Model\n",
    "    if not os.path.exists('crnn_best_model.keras'):\n",
    "        print(\"âŒ Error: 'crnn_best_model.keras' not found. Did the training finish?\")\n",
    "        return\n",
    "\n",
    "    print(\"ğŸ“¥ Loading saved model...\")\n",
    "    best_model = keras.models.load_model('crnn_best_model.keras')\n",
    "    \n",
    "    # 3. Evaluate\n",
    "    print(\"\\nğŸ“Š Evaluating model performance...\")\n",
    "    test_loss, test_acc = best_model.evaluate(X_test, y_test, verbose=1)\n",
    "    print(f\"   Final Test Accuracy: {test_acc:.4f}\")\n",
    "    \n",
    "    # 4. Generate Predictions\n",
    "    print(\"\\nğŸ’¾ Generating predictions CSV...\")\n",
    "    y_pred_probs = best_model.predict(X_test, verbose=0)\n",
    "    y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "    y_true = np.argmax(y_test, axis=1)\n",
    "    \n",
    "    # This is the part that failed previously\n",
    "    results_df = pd.DataFrame({\n",
    "        'true_emotion': label_encoder.inverse_transform(y_true),\n",
    "        'predicted_emotion': label_encoder.inverse_transform(y_pred),\n",
    "        'confidence': np.max(y_pred_probs, axis=1)\n",
    "    })\n",
    "    results_df.to_csv('crnn_predictions.csv', index=False)\n",
    "    print(\"âœ… Saved to 'crnn_predictions.csv'\")\n",
    "    \n",
    "    # 5. Plot History from CSV Log\n",
    "    # Since the 'history' object is lost, we read the CSV log file created during training\n",
    "    if os.path.exists('training_history_crnn.csv'):\n",
    "        print(\"\\nğŸ“ˆ Plotting training history from logs...\")\n",
    "        history_df = pd.read_csv('training_history_crnn.csv')\n",
    "        \n",
    "        plt.figure(figsize=(12, 5))\n",
    "        \n",
    "        # Accuracy\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(history_df['accuracy'], label='Train Accuracy')\n",
    "        plt.plot(history_df['val_accuracy'], label='Val Accuracy')\n",
    "        plt.title('Training History: Accuracy')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        \n",
    "        # Loss\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(history_df['loss'], label='Train Loss')\n",
    "        plt.plot(history_df['val_loss'], label='Val Loss')\n",
    "        plt.title('Training History: Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('crnn_training_plot.png')\n",
    "        plt.show()\n",
    "        print(\"âœ… Plot saved to 'crnn_training_plot.png'\")\n",
    "    else:\n",
    "        print(\"âš ï¸ 'training_history_crnn.csv' not found, skipping plots.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    continue_evaluation_only()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "acf5e3ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ Resuming pipeline for Detailed Evaluation...\n",
      "ğŸ“¥ Loading data...\n",
      "ğŸ§  Loading saved model...\n",
      "\n",
      "âš¡ Generating predictions...\n",
      "\u001b[1m298/298\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step\n",
      "\n",
      "========================================\n",
      "ğŸ“Š FINAL EVALUATION METRICS\n",
      "========================================\n",
      "âœ… Overall Accuracy:  0.9153 (91.53%)\n",
      "âœ… Weighted Precision: 0.9152\n",
      "âœ… Weighted Recall:    0.9153\n",
      "âœ… Weighted F1-Score:  0.9153\n",
      "\n",
      "ğŸ“‹ DETAILED CLASSIFICATION REPORT\n",
      "------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.92      0.91      0.91      1902\n",
      "       happy       0.87      0.87      0.87      1902\n",
      "     neutral       0.94      0.94      0.94      1894\n",
      "         sad       0.94      0.95      0.95      1902\n",
      "    surprise       0.91      0.91      0.91      1930\n",
      "\n",
      "    accuracy                           0.92      9530\n",
      "   macro avg       0.92      0.92      0.92      9530\n",
      "weighted avg       0.92      0.92      0.92      9530\n",
      "\n",
      "\n",
      "ğŸ“‰ CONFUSION MATRIX\n",
      "------------------------------------------------------------\n",
      "[[1726   86   26   10   54]\n",
      " [  74 1655   31   21  121]\n",
      " [  18   19 1784   71    2]\n",
      " [  11   20   66 1802    3]\n",
      " [  53  113    1    7 1756]]\n",
      "\n",
      "ğŸ’¾ Predictions saved to 'crnn_predictions_full.csv'\n"
     ]
    }
   ],
   "source": [
    "# =====================\n",
    "# CONTINUATION SCRIPT WITH FULL METRICS\n",
    "# =====================\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "\n",
    "# --- Re-define Load Function ---\n",
    "def load_real_data(features_file='unified_audio_features.h5'):\n",
    "    with h5py.File(features_file, 'r') as hf:\n",
    "        features = hf['features'][:]\n",
    "        emotions = [e.decode('utf-8') for e in hf['emotions'][:]]\n",
    "    \n",
    "    # Expand dims for channel\n",
    "    features = np.expand_dims(features, axis=-1)\n",
    "    \n",
    "    # Re-encode labels\n",
    "    label_encoder = LabelEncoder()\n",
    "    emotion_labels = label_encoder.fit_transform(emotions)\n",
    "    onehot_labels = keras.utils.to_categorical(emotion_labels, 5)\n",
    "    \n",
    "    return features, onehot_labels, label_encoder\n",
    "\n",
    "def continue_evaluation_with_metrics():\n",
    "    print(\"ğŸ”„ Resuming pipeline for Detailed Evaluation...\")\n",
    "    \n",
    "    # 1. Reload Data\n",
    "    print(\"ğŸ“¥ Loading data...\")\n",
    "    X, y, label_encoder = load_real_data()\n",
    "    \n",
    "    y_integers = np.argmax(y, axis=1)\n",
    "    _, X_test, _, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y_integers\n",
    "    )\n",
    "    \n",
    "    # 2. Load Model\n",
    "    if not os.path.exists('crnn_best_model.keras'):\n",
    "        print(\"âŒ Error: 'crnn_best_model.keras' not found.\")\n",
    "        return\n",
    "\n",
    "    print(\"ğŸ§  Loading saved model...\")\n",
    "    best_model = keras.models.load_model('crnn_best_model.keras')\n",
    "    \n",
    "    # 3. Generate Predictions\n",
    "    print(\"\\nâš¡ Generating predictions...\")\n",
    "    y_pred_probs = best_model.predict(X_test, verbose=1)\n",
    "    y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "    y_true = np.argmax(y_test, axis=1)\n",
    "    \n",
    "    # 4. Calculate Comprehensive Metrics\n",
    "    print(\"\\n\" + \"=\"*40)\n",
    "    print(\"ğŸ“Š FINAL EVALUATION METRICS\")\n",
    "    print(\"=\"*40)\n",
    "    \n",
    "    # Accuracy\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    \n",
    "    # Precision, Recall, F1 (Weighted average accounts for class imbalance)\n",
    "    prec = precision_score(y_true, y_pred, average='weighted')\n",
    "    rec = recall_score(y_true, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "    \n",
    "    print(f\"âœ… Overall Accuracy:  {acc:.4f} ({acc*100:.2f}%)\")\n",
    "    print(f\"âœ… Weighted Precision: {prec:.4f}\")\n",
    "    print(f\"âœ… Weighted Recall:    {rec:.4f}\")\n",
    "    print(f\"âœ… Weighted F1-Score:  {f1:.4f}\")\n",
    "    \n",
    "    print(\"\\nğŸ“‹ DETAILED CLASSIFICATION REPORT\")\n",
    "    print(\"-\" * 60)\n",
    "    print(classification_report(y_true, y_pred, target_names=label_encoder.classes_))\n",
    "    \n",
    "    print(\"\\nğŸ“‰ CONFUSION MATRIX\")\n",
    "    print(\"-\" * 60)\n",
    "    print(confusion_matrix(y_true, y_pred))\n",
    "    \n",
    "    # 5. Save Results\n",
    "    results_df = pd.DataFrame({\n",
    "        'true_emotion': label_encoder.inverse_transform(y_true),\n",
    "        'predicted_emotion': label_encoder.inverse_transform(y_pred),\n",
    "        'confidence': np.max(y_pred_probs, axis=1)\n",
    "    })\n",
    "    results_df.to_csv('crnn_predictions_full.csv', index=False)\n",
    "    print(f\"\\nğŸ’¾ Predictions saved to 'crnn_predictions_full.csv'\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    continue_evaluation_with_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "238d31ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¥ Loading data from unified_audio_features.h5...\n",
      "âœ… Data Loaded: (47648, 129, 13, 1) samples\n",
      "ğŸ”¹ Training Set: (38118, 129, 13, 1)\n",
      "ğŸ”¹ Test Set:     (9530, 129, 13, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Regularized_CRNN_GRU\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"Regularized_CRNN_GRU\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ input_layer_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)     â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2d_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_16          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ activation_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)    â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling2d_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)      â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)      â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2d_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_17          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ activation_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling2d_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2d_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)     â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_18          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)     â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ activation_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)     â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling2d_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)     â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)     â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ permute_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Permute</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)     â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ reshape_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)        â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ bidirectional_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">811,776</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ bidirectional_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">74,496</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_19          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ activation_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">325</span> â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ input_layer_6 (\u001b[38;5;33mInputLayer\u001b[0m)      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m129\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m1\u001b[0m)     â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2d_22 (\u001b[38;5;33mConv2D\u001b[0m)              â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m129\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m32\u001b[0m)    â”‚           \u001b[38;5;34m320\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_16          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m129\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m32\u001b[0m)    â”‚           \u001b[38;5;34m128\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ activation_12 (\u001b[38;5;33mActivation\u001b[0m)      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m129\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m32\u001b[0m)    â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling2d_18 (\u001b[38;5;33mMaxPooling2D\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m32\u001b[0m)      â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_27 (\u001b[38;5;33mDropout\u001b[0m)            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m32\u001b[0m)      â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2d_23 (\u001b[38;5;33mConv2D\u001b[0m)              â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)      â”‚        \u001b[38;5;34m18,496\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_17          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)      â”‚           \u001b[38;5;34m256\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ activation_13 (\u001b[38;5;33mActivation\u001b[0m)      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)      â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling2d_19 (\u001b[38;5;33mMaxPooling2D\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m64\u001b[0m)      â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_28 (\u001b[38;5;33mDropout\u001b[0m)            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m64\u001b[0m)      â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2d_24 (\u001b[38;5;33mConv2D\u001b[0m)              â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m128\u001b[0m)     â”‚        \u001b[38;5;34m73,856\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_18          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m128\u001b[0m)     â”‚           \u001b[38;5;34m512\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ activation_14 (\u001b[38;5;33mActivation\u001b[0m)      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m128\u001b[0m)     â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling2d_20 (\u001b[38;5;33mMaxPooling2D\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)     â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_29 (\u001b[38;5;33mDropout\u001b[0m)            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)     â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ permute_3 (\u001b[38;5;33mPermute\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)     â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ reshape_3 (\u001b[38;5;33mReshape\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m2048\u001b[0m)        â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ bidirectional_6 (\u001b[38;5;33mBidirectional\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)         â”‚       \u001b[38;5;34m811,776\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ bidirectional_7 (\u001b[38;5;33mBidirectional\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚        \u001b[38;5;34m74,496\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_14 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚         \u001b[38;5;34m8,256\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_19          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚           \u001b[38;5;34m256\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ activation_15 (\u001b[38;5;33mActivation\u001b[0m)      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_30 (\u001b[38;5;33mDropout\u001b[0m)            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_15 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              â”‚           \u001b[38;5;34m325\u001b[0m â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">988,677</span> (3.77 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m988,677\u001b[0m (3.77 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">988,101</span> (3.77 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m988,101\u001b[0m (3.77 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">576</span> (2.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m576\u001b[0m (2.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸš€ Starting Training (Regularized GRU + SpecAugment)...\n",
      "Epoch 1/100\n",
      "\u001b[1m 371/1192\u001b[0m \u001b[32mâ”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m26s\u001b[0m 32ms/step - accuracy: 0.2088 - loss: 2.1757"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 271\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mğŸ’¾ Results saved to \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcrnn_regularized_predictions.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 271\u001b[0m     \u001b[43mmain_training_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[28], line 201\u001b[0m, in \u001b[0;36mmain_training_pipeline\u001b[0;34m()\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# F. Train\u001b[39;00m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mğŸš€ Starting Training (Regularized GRU + SpecAugment)...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 201\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;66;03m# ==========================================\u001b[39;00m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;66;03m# 5. DETAILED EVALUATION\u001b[39;00m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;66;03m# ==========================================\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m40\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py:368\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[1;32m    367\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 368\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    369\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[1;32m    370\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py:216\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfunction\u001b[39m(iterator):\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m    214\u001b[0m         iterator, (tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mIterator, tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mDistributedIterator)\n\u001b[1;32m    215\u001b[0m     ):\n\u001b[0;32m--> 216\u001b[0m         opt_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs\u001b[38;5;241m.\u001b[39mhas_value():\n\u001b[1;32m    218\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1683\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1681\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1682\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1683\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1684\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1685\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1686\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1687\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1688\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1689\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1690\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1691\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1692\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1693\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1697\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1698\u001b[0m   )\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# STRATEGY C: REGULARIZED GRU + ROBUST SPECAUGMENT\n",
    "# ==========================================\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models, regularizers, backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import h5py\n",
    "\n",
    "# ==========================================\n",
    "# 1. DATA LOADING\n",
    "# ==========================================\n",
    "def load_real_data(features_file='unified_audio_features.h5'):\n",
    "    print(f\"ğŸ“¥ Loading data from {features_file}...\")\n",
    "    \n",
    "    if not os.path.exists(features_file):\n",
    "        raise FileNotFoundError(f\"âŒ Error: File '{features_file}' not found.\")\n",
    "\n",
    "    with h5py.File(features_file, 'r') as hf:\n",
    "        features = hf['features'][:]\n",
    "        emotions = [e.decode('utf-8') for e in hf['emotions'][:]]\n",
    "    \n",
    "    # Expand dims for channel (e.g., 128, 128) -> (128, 128, 1)\n",
    "    features = np.expand_dims(features, axis=-1)\n",
    "    \n",
    "    # Re-encode labels\n",
    "    label_encoder = LabelEncoder()\n",
    "    emotion_labels = label_encoder.fit_transform(emotions)\n",
    "    num_classes = len(np.unique(emotion_labels))\n",
    "    onehot_labels = keras.utils.to_categorical(emotion_labels, num_classes)\n",
    "    \n",
    "    print(f\"âœ… Data Loaded: {features.shape} samples\")\n",
    "    return features, onehot_labels, label_encoder, num_classes\n",
    "\n",
    "# ==========================================\n",
    "# 2. ROBUST SPECAUGMENT IMPLEMENTATION\n",
    "# ==========================================\n",
    "def spec_augment(spectrogram, num_freq_masks=2, num_time_masks=2, freq_mask_param=15, time_mask_param=20):\n",
    "    \"\"\"\n",
    "    Applies SpecAugment with safety checks for small dimensions.\n",
    "    \"\"\"\n",
    "    aug_spectrogram = tf.identity(spectrogram)\n",
    "    shape = tf.shape(aug_spectrogram)\n",
    "    height = shape[0]\n",
    "    width = shape[1]\n",
    "    \n",
    "    # Cast params to int32\n",
    "    freq_mask_param = tf.cast(freq_mask_param, tf.int32)\n",
    "    time_mask_param = tf.cast(time_mask_param, tf.int32)\n",
    "    \n",
    "    # --- Frequency Masking ---\n",
    "    for _ in range(num_freq_masks):\n",
    "        # ğŸ›¡ï¸ SAFETY FIX: Ensure mask height is never larger than image height - 1\n",
    "        # If image is 13px high, mask can be at most 12px.\n",
    "        safe_f_max = tf.maximum(1, tf.minimum(freq_mask_param, height - 1))\n",
    "        \n",
    "        f = tf.random.uniform([], minval=0, maxval=safe_f_max, dtype=tf.int32)\n",
    "        f0 = tf.random.uniform([], minval=0, maxval=height - f, dtype=tf.int32)\n",
    "        \n",
    "        mask_start = f0\n",
    "        mask_end = f0 + f\n",
    "        indices = tf.range(height)\n",
    "        mask = (indices < mask_start) | (indices >= mask_end)\n",
    "        mask = tf.reshape(mask, (height, 1, 1))\n",
    "        mask = tf.cast(mask, aug_spectrogram.dtype)\n",
    "        aug_spectrogram = aug_spectrogram * mask\n",
    "\n",
    "    # --- Time Masking ---\n",
    "    for _ in range(num_time_masks):\n",
    "        # ğŸ›¡ï¸ SAFETY FIX: Ensure mask width is never larger than image width - 1\n",
    "        safe_t_max = tf.maximum(1, tf.minimum(time_mask_param, width - 1))\n",
    "        \n",
    "        t = tf.random.uniform([], minval=0, maxval=safe_t_max, dtype=tf.int32)\n",
    "        t0 = tf.random.uniform([], minval=0, maxval=width - t, dtype=tf.int32)\n",
    "        \n",
    "        mask_start = t0\n",
    "        mask_end = t0 + t\n",
    "        indices = tf.range(width)\n",
    "        mask = (indices < mask_start) | (indices >= mask_end)\n",
    "        mask = tf.reshape(mask, (1, width, 1))\n",
    "        mask = tf.cast(mask, aug_spectrogram.dtype)\n",
    "        aug_spectrogram = aug_spectrogram * mask\n",
    "\n",
    "    return aug_spectrogram\n",
    "\n",
    "def apply_spec_augment_wrapper(image, label):\n",
    "    # Wrapper for tf.data pipeline\n",
    "    return spec_augment(image), label\n",
    "\n",
    "# ==========================================\n",
    "# 3. REGULARIZED CRNN ARCHITECTURE\n",
    "# ==========================================\n",
    "def build_regularized_crnn(input_shape, num_classes):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "\n",
    "    # --- CNN Block (Feature Extraction) ---\n",
    "    x = layers.Conv2D(32, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.001))(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('elu')(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    x = layers.Dropout(0.2)(x) \n",
    "\n",
    "    x = layers.Conv2D(64, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.001))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('elu')(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "\n",
    "    x = layers.Conv2D(128, (3, 3), padding='same', kernel_regularizer=regularizers.l2(0.001))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('elu')(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "\n",
    "    # --- Bridge to RNN ---\n",
    "    # Permute to (Batch, Time, Freq, Channels)\n",
    "    x = layers.Permute((2, 1, 3))(x) \n",
    "    \n",
    "    # Reshape: Combine Frequency and Channels into 'Features'\n",
    "    target_shape = (-1, x.shape[2] * x.shape[3])\n",
    "    x = layers.Reshape(target_shape=(x.shape[1], x.shape[2] * x.shape[3]))(x)\n",
    "    \n",
    "    # --- RNN Block (Regularized GRU) ---\n",
    "    x = layers.Bidirectional(\n",
    "        layers.GRU(64, return_sequences=True, dropout=0.4, recurrent_dropout=0.0)\n",
    "    )(x)\n",
    "    \n",
    "    x = layers.Bidirectional(\n",
    "        layers.GRU(64, return_sequences=False, dropout=0.4, recurrent_dropout=0.0)\n",
    "    )(x)\n",
    "\n",
    "    # --- Output Block ---\n",
    "    x = layers.Dense(64, kernel_regularizer=regularizers.l2(0.001))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('elu')(x)\n",
    "    x = layers.Dropout(0.4)(x) \n",
    "\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = models.Model(inputs=inputs, outputs=outputs, name=\"Regularized_CRNN_GRU\")\n",
    "    return model\n",
    "\n",
    "# ==========================================\n",
    "# 4. EXECUTION PIPELINE\n",
    "# ==========================================\n",
    "def main_training_pipeline():\n",
    "    # A. Load Data\n",
    "    try:\n",
    "        X, y, label_encoder, num_classes = load_real_data()\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data: {e}\")\n",
    "        return\n",
    "\n",
    "    # B. Split Data\n",
    "    y_integers = np.argmax(y, axis=1)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y_integers\n",
    "    )\n",
    "    \n",
    "    print(f\"ğŸ”¹ Training Set: {X_train.shape}\")\n",
    "    print(f\"ğŸ”¹ Test Set:     {X_test.shape}\")\n",
    "\n",
    "    # C. Create TF Datasets\n",
    "    BATCH_SIZE = 32\n",
    "\n",
    "    # Train Dataset (With Safe Augmentation)\n",
    "    train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "    train_ds = train_ds.shuffle(buffer_size=1000)\n",
    "    train_ds = train_ds.map(apply_spec_augment_wrapper, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    train_ds = train_ds.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    # Test Dataset (No Augmentation)\n",
    "    val_ds = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
    "    val_ds = val_ds.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    # D. Build Model\n",
    "    input_shape = X_train.shape[1:] \n",
    "    model = build_regularized_crnn(input_shape, num_classes)\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "\n",
    "    # E. Callbacks\n",
    "    callbacks = [\n",
    "        tf.keras.callbacks.ModelCheckpoint('crnn_best_model_regularized.keras', save_best_only=True, monitor='val_accuracy'),\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=5, min_lr=1e-6),\n",
    "        tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=12, restore_best_weights=True)\n",
    "    ]\n",
    "\n",
    "    # F. Train\n",
    "    print(\"\\nğŸš€ Starting Training (Regularized GRU + SpecAugment)...\")\n",
    "    history = model.fit(train_ds, validation_data=val_ds, epochs=100, callbacks=callbacks)\n",
    "\n",
    "    # ==========================================\n",
    "    # 5. DETAILED EVALUATION\n",
    "    # ==========================================\n",
    "    print(\"\\n\" + \"=\"*40)\n",
    "    print(\"ğŸ“Š FINAL EVALUATION METRICS\")\n",
    "    print(\"=\"*40)\n",
    "    \n",
    "    # Load best weights\n",
    "    model.load_weights('crnn_best_model_regularized.keras')\n",
    "    \n",
    "    # Generate Predictions\n",
    "    y_pred_probs = model.predict(X_test)\n",
    "    y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "    y_true = np.argmax(y_test, axis=1)\n",
    "    \n",
    "    # Metrics\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred, average='weighted')\n",
    "    rec = recall_score(y_true, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "    \n",
    "    print(f\"âœ… Overall Accuracy:  {acc:.4f} ({acc*100:.2f}%)\")\n",
    "    print(f\"âœ… Weighted Precision: {prec:.4f}\")\n",
    "    print(f\"âœ… Weighted Recall:    {rec:.4f}\")\n",
    "    print(f\"âœ… Weighted F1-Score:  {f1:.4f}\")\n",
    "    \n",
    "    print(\"\\nğŸ“‹ CLASSIFICATION REPORT\")\n",
    "    print(\"-\" * 60)\n",
    "    print(classification_report(y_true, y_pred, target_names=label_encoder.classes_))\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)\n",
    "    plt.title('Confusion Matrix - Regularized CRNN')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.savefig('confusion_matrix_regularized.png')\n",
    "    plt.show()\n",
    "    \n",
    "    # Training History\n",
    "    if history is not None:\n",
    "        plt.figure(figsize=(12, 5))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(history.history['accuracy'], label='Train Acc')\n",
    "        plt.plot(history.history['val_accuracy'], label='Val Acc')\n",
    "        plt.title('Accuracy')\n",
    "        plt.legend()\n",
    "        \n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(history.history['loss'], label='Train Loss')\n",
    "        plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "        plt.title('Loss')\n",
    "        plt.legend()\n",
    "        plt.savefig('training_history_regularized.png')\n",
    "        plt.show()\n",
    "\n",
    "    # Save Predictions CSV\n",
    "    results_df = pd.DataFrame({\n",
    "        'true_emotion': label_encoder.inverse_transform(y_true),\n",
    "        'predicted_emotion': label_encoder.inverse_transform(y_pred),\n",
    "        'confidence': np.max(y_pred_probs, axis=1)\n",
    "    })\n",
    "    results_df.to_csv('crnn_regularized_predictions.csv', index=False)\n",
    "    print(f\"\\nğŸ’¾ Results saved to 'crnn_regularized_predictions.csv'\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main_training_pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247dd515",
   "metadata": {},
   "source": [
    "the results for the above STRATEGY C: REGULARIZED GRU + ROBUST SPECAUGMENT are in the last script in pipeline.ipynb file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
